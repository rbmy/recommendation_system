2024-12-10 23:47:49,427 Using device cuda.
2024-12-10 23:47:49,427 Experiment setup: {'batch_size': 1024, 'LR': 0.001, 'K': 10, 'name': 'batch_1024'}
2024-12-10 23:47:56,690 [Iteration 0/5000] train_loss: -1.50465, val_loss: -0.88453, val_recall@10: 0.00079, val_precision@10: 0.00072, val_ndcg@10: 0.00093
2024-12-10 23:48:05,119 [Iteration 200/5000] train_loss: -1153714356224.0, val_loss: -116809621504.0, val_recall@10: 0.00464, val_precision@10: 0.00253, val_ndcg@10: 0.00312
2024-12-10 23:48:13,451 [Iteration 400/5000] train_loss: -2.2137383289041715e+17, val_loss: -8.316661284837786e+16, val_recall@10: 0.01206, val_precision@10: 0.00976, val_ndcg@10: 0.01259
2024-12-10 23:48:21,666 [Iteration 600/5000] train_loss: -6.919088399012059e+20, val_loss: -2.6188428314722225e+20, val_recall@10: 0.01767, val_precision@10: 0.01338, val_ndcg@10: 0.01677
2024-12-10 23:48:29,865 [Iteration 800/5000] train_loss: -3.7590172491775182e+22, val_loss: -1.329203540431206e+22, val_recall@10: 0.02558, val_precision@10: 0.01519, val_ndcg@10: 0.01952
2024-12-10 23:48:38,045 [Iteration 1000/5000] train_loss: -5.735020674922262e+22, val_loss: -2.1573737410180963e+22, val_recall@10: 0.02373, val_precision@10: 0.01374, val_ndcg@10: 0.01821
2024-12-10 23:48:46,840 [Iteration 1200/5000] train_loss: -6.814212849309501e+22, val_loss: -2.774159048845051e+22, val_recall@10: 0.02212, val_precision@10: 0.01374, val_ndcg@10: 0.01832
2024-12-10 23:48:55,253 [Iteration 1400/5000] train_loss: -1.3399307769736304e+23, val_loss: -3.0693774353585723e+22, val_recall@10: 0.02076, val_precision@10: 0.01338, val_ndcg@10: 0.01743
2024-12-10 23:49:03,486 [Iteration 1600/5000] train_loss: -4.919201708903426e+22, val_loss: -3.975982664825719e+22, val_recall@10: 0.01717, val_precision@10: 0.01284, val_ndcg@10: 0.01637
2024-12-10 23:49:11,690 [Iteration 1800/5000] train_loss: -1.563326432169791e+23, val_loss: -3.2616583962691742e+22, val_recall@10: 0.01685, val_precision@10: 0.01248, val_ndcg@10: 0.01584
2024-12-10 23:49:20,008 [Iteration 2000/5000] train_loss: -4.566398270934513e+22, val_loss: -5.101859603310244e+22, val_recall@10: 0.01505, val_precision@10: 0.0123, val_ndcg@10: 0.01522
2024-12-10 23:49:28,291 [Iteration 2200/5000] train_loss: -1.933684451126231e+22, val_loss: -5.823634401910329e+22, val_recall@10: 0.01245, val_precision@10: 0.01139, val_ndcg@10: 0.01483
2024-12-10 23:49:36,523 [Iteration 2400/5000] train_loss: -3.146014064317629e+22, val_loss: -6.3663014936898525e+22, val_recall@10: 0.01249, val_precision@10: 0.01157, val_ndcg@10: 0.01469
2024-12-10 23:49:44,823 [Iteration 2600/5000] train_loss: -1.9548238974171455e+22, val_loss: -6.732019453950213e+22, val_recall@10: 0.01319, val_precision@10: 0.01157, val_ndcg@10: 0.01522
2024-12-10 23:49:53,120 [Iteration 2800/5000] train_loss: -2.193276437247494e+23, val_loss: -5.678023118038261e+22, val_recall@10: 0.01604, val_precision@10: 0.0123, val_ndcg@10: 0.01597
2024-12-10 23:50:01,479 [Iteration 3000/5000] train_loss: -4.508877846133774e+22, val_loss: -5.567788960319076e+22, val_recall@10: 0.01596, val_precision@10: 0.0123, val_ndcg@10: 0.01594
2024-12-10 23:50:09,797 [Iteration 3200/5000] train_loss: -8.40339174478025e+22, val_loss: -6.456142901936341e+22, val_recall@10: 0.01596, val_precision@10: 0.0123, val_ndcg@10: 0.01606
2024-12-10 23:50:18,179 [Iteration 3400/5000] train_loss: -1.841733196526312e+23, val_loss: -8.08567900402792e+22, val_recall@10: 0.01453, val_precision@10: 0.01175, val_ndcg@10: 0.01527
2024-12-10 23:50:26,413 [Iteration 3600/5000] train_loss: -7.638495880468017e+22, val_loss: -7.947605845212144e+22, val_recall@10: 0.01592, val_precision@10: 0.01212, val_ndcg@10: 0.01591
2024-12-10 23:50:34,692 [Iteration 3800/5000] train_loss: -7.749458270246948e+22, val_loss: -9.141720874890623e+22, val_recall@10: 0.01554, val_precision@10: 0.01157, val_ndcg@10: 0.01548
2024-12-10 23:50:43,091 [Iteration 4000/5000] train_loss: -6.457235475205941e+22, val_loss: -9.002574958643608e+22, val_recall@10: 0.01516, val_precision@10: 0.01103, val_ndcg@10: 0.01516
2024-12-10 23:50:51,484 [Iteration 4200/5000] train_loss: -1.753161623230757e+23, val_loss: -8.822089600697033e+22, val_recall@10: 0.01518, val_precision@10: 0.01121, val_ndcg@10: 0.01527
2024-12-10 23:50:59,785 [Iteration 4400/5000] train_loss: -5.806539638444756e+22, val_loss: -9.146830659027838e+22, val_recall@10: 0.01518, val_precision@10: 0.01121, val_ndcg@10: 0.01524
2024-12-10 23:51:08,041 [Iteration 4600/5000] train_loss: -5.316755614929668e+22, val_loss: -9.852387995369762e+22, val_recall@10: 0.01555, val_precision@10: 0.01139, val_ndcg@10: 0.01545
2024-12-10 23:51:16,423 [Iteration 4800/5000] train_loss: -8.341753678840206e+22, val_loss: -8.277229706258943e+22, val_recall@10: 0.01555, val_precision@10: 0.01139, val_ndcg@10: 0.01562
2024-12-10 23:51:24,818 [Iteration 4999/5000] train_loss: -5.497626030644383e+22, val_loss: -1.0560694328924233e+23, val_recall@10: 0.01555, val_precision@10: 0.01139, val_ndcg@10: 0.01585
2024-12-10 23:54:59,213 Using device cuda.
2024-12-10 23:54:59,214 Experiment setup: {'batch_size': 1024, 'LR': 0.001, 'K': 10, 'name': 'batch_1024'}
2024-12-10 23:55:06,468 [Iteration 0/5000] train_loss: -1.11284, val_loss: -0.50504, val_recall@10: 0.00078, val_precision@10: 0.0009, val_ndcg@10: 0.00101
2024-12-10 23:55:14,970 [Iteration 200/5000] train_loss: -42690150400.0, val_loss: -20600145920.0, val_recall@10: 0.00136, val_precision@10: 0.00253, val_ndcg@10: 0.00252
2024-12-10 23:55:23,561 [Iteration 400/5000] train_loss: -2.1894225004068864e+16, val_loss: -3.28577346174976e+16, val_recall@10: 0.00622, val_precision@10: 0.00723, val_ndcg@10: 0.0078
2024-12-10 23:55:32,262 [Iteration 600/5000] train_loss: -3.235066498204398e+20, val_loss: -1.210268424713504e+20, val_recall@10: 0.01345, val_precision@10: 0.01193, val_ndcg@10: 0.01393
2024-12-10 23:55:40,785 [Iteration 800/5000] train_loss: -4.443736430043599e+22, val_loss: -7.503946112820715e+21, val_recall@10: 0.0157, val_precision@10: 0.01356, val_ndcg@10: 0.01626
2024-12-10 23:55:49,111 [Iteration 1000/5000] train_loss: -3.4504425372491044e+22, val_loss: -1.2947926615783748e+22, val_recall@10: 0.01783, val_precision@10: 0.0141, val_ndcg@10: 0.01758
2024-12-10 23:55:57,626 [Iteration 1200/5000] train_loss: -1.081106429408853e+22, val_loss: -1.6550144288534921e+22, val_recall@10: 0.02027, val_precision@10: 0.01483, val_ndcg@10: 0.01884
2024-12-10 23:56:06,030 [Iteration 1400/5000] train_loss: -3.2896039074969523e+22, val_loss: -2.2423352738883475e+22, val_recall@10: 0.01685, val_precision@10: 0.01374, val_ndcg@10: 0.01728
2024-12-10 23:56:14,746 [Iteration 1600/5000] train_loss: -1.6162343828221675e+22, val_loss: -2.873673288371206e+22, val_recall@10: 0.01876, val_precision@10: 0.0141, val_ndcg@10: 0.01792
2024-12-10 23:56:23,237 [Iteration 1800/5000] train_loss: -2.029927951423008e+22, val_loss: -2.787381166991048e+22, val_recall@10: 0.01904, val_precision@10: 0.01429, val_ndcg@10: 0.01809
2024-12-10 23:56:32,189 [Iteration 2000/5000] train_loss: -6.333819281377443e+22, val_loss: -3.2981535410295524e+22, val_recall@10: 0.02037, val_precision@10: 0.01374, val_ndcg@10: 0.01819
2024-12-10 23:56:41,711 [Iteration 2200/5000] train_loss: -4.006214878764295e+22, val_loss: -4.291102683272572e+22, val_recall@10: 0.01741, val_precision@10: 0.01266, val_ndcg@10: 0.01683
2024-12-10 23:56:51,555 [Iteration 2400/5000] train_loss: -5.968954753246469e+22, val_loss: -4.040866475017209e+22, val_recall@10: 0.01889, val_precision@10: 0.01266, val_ndcg@10: 0.01723
2024-12-10 23:57:01,261 [Iteration 2600/5000] train_loss: -3.993471042898724e+22, val_loss: -5.092088143198738e+22, val_recall@10: 0.01884, val_precision@10: 0.01248, val_ndcg@10: 0.0172
2024-12-10 23:57:10,985 [Iteration 2800/5000] train_loss: -9.108360911010839e+22, val_loss: -5.613710364279522e+22, val_recall@10: 0.01709, val_precision@10: 0.01248, val_ndcg@10: 0.01685
2024-12-10 23:57:20,744 [Iteration 3000/5000] train_loss: -3.3764607802703824e+22, val_loss: -5.451630767650048e+22, val_recall@10: 0.01692, val_precision@10: 0.0123, val_ndcg@10: 0.01673
2024-12-10 23:57:30,591 [Iteration 3200/5000] train_loss: -6.972055459409545e+22, val_loss: -5.486740379985065e+22, val_recall@10: 0.01687, val_precision@10: 0.01212, val_ndcg@10: 0.01664
2024-12-10 23:57:40,686 [Iteration 3400/5000] train_loss: -9.488899767284913e+22, val_loss: -5.907316236946463e+22, val_recall@10: 0.01702, val_precision@10: 0.0123, val_ndcg@10: 0.01668
2024-12-10 23:57:50,924 [Iteration 3600/5000] train_loss: -3.002157833220347e+22, val_loss: -6.613316277131758e+22, val_recall@10: 0.01685, val_precision@10: 0.01212, val_ndcg@10: 0.01659
2024-12-10 23:58:01,141 [Iteration 3800/5000] train_loss: -3.884874844364014e+22, val_loss: -5.231007978744459e+22, val_recall@10: 0.01685, val_precision@10: 0.01212, val_ndcg@10: 0.01663
2024-12-10 23:58:10,893 [Iteration 4000/5000] train_loss: -1.7519959565392046e+22, val_loss: -6.276131322670566e+22, val_recall@10: 0.01702, val_precision@10: 0.0123, val_ndcg@10: 0.01674
2024-12-10 23:59:01,905 [Iteration 4200/5000] train_loss: -2.6169525721923733e+22, val_loss: -6.2682756938405436e+22, val_recall@10: 0.01702, val_precision@10: 0.0123, val_ndcg@10: 0.01671
2024-12-11 00:00:58,239 [Iteration 4400/5000] train_loss: -8.266775950803891e+22, val_loss: -7.974020357746597e+22, val_recall@10: 0.01595, val_precision@10: 0.01175, val_ndcg@10: 0.01618
2024-12-11 00:02:50,544 [Iteration 4600/5000] train_loss: -1.0468404763920306e+23, val_loss: -7.985496430317063e+22, val_recall@10: 0.01574, val_precision@10: 0.01139, val_ndcg@10: 0.01595
2024-12-11 00:04:18,722 [Iteration 4800/5000] train_loss: -9.539377012628407e+22, val_loss: -8.036611385367792e+22, val_recall@10: 0.01574, val_precision@10: 0.01139, val_ndcg@10: 0.01588
2024-12-11 00:04:29,753 [Iteration 4999/5000] train_loss: -1.0897496927777061e+23, val_loss: -8.27470678974769e+22, val_recall@10: 0.01574, val_precision@10: 0.01139, val_ndcg@10: 0.01588
2024-12-11 00:04:29,889 Experiment batch_1024: best train loss -1.0897496927777061e+23; best val loss -1.0897496927777061e+23; last train loss -1.0897496927777061e+23; last val loss -1.0897496927777061e+23
2024-12-11 00:04:29,889 Experiment setup: {'batch_size': 512, 'LR': 0.001, 'K': 10, 'name': 'batch_512'}
2024-12-11 00:04:37,019 [Iteration 0/5000] train_loss: -1.45921, val_loss: -0.70086, val_recall@10: 0.00017, val_precision@10: 0.00036, val_ndcg@10: 0.00057
2024-12-11 00:04:48,141 [Iteration 200/5000] train_loss: -1195479424.0, val_loss: -2310777088.0, val_recall@10: 0.0007, val_precision@10: 0.00108, val_ndcg@10: 0.0011
2024-12-11 00:04:59,170 [Iteration 400/5000] train_loss: -1181208885067776.0, val_loss: -1960027250229248.0, val_recall@10: 0.00705, val_precision@10: 0.0047, val_ndcg@10: 0.00628
2024-12-11 00:05:10,140 [Iteration 600/5000] train_loss: -1.3421050145982644e+19, val_loss: -7.930824100392468e+18, val_recall@10: 0.01096, val_precision@10: 0.00868, val_ndcg@10: 0.01133
2024-12-11 00:05:21,158 [Iteration 800/5000] train_loss: -7.912700696300209e+20, val_loss: -1.7102439288187828e+21, val_recall@10: 0.01016, val_precision@10: 0.00904, val_ndcg@10: 0.012
2024-12-11 00:05:32,469 [Iteration 1000/5000] train_loss: -1.3952088595199013e+22, val_loss: -9.30718064822042e+21, val_recall@10: 0.01037, val_precision@10: 0.00976, val_ndcg@10: 0.01248
2024-12-11 00:05:43,937 [Iteration 1200/5000] train_loss: -2.128652034394541e+22, val_loss: -1.7459965988855936e+22, val_recall@10: 0.00893, val_precision@10: 0.00886, val_ndcg@10: 0.01233
2024-12-11 00:05:55,720 [Iteration 1400/5000] train_loss: -2.8368583880372845e+22, val_loss: -2.43603959746118e+22, val_recall@10: 0.00912, val_precision@10: 0.00904, val_ndcg@10: 0.01168
2024-12-11 00:06:07,615 [Iteration 1600/5000] train_loss: -5.439296759350568e+22, val_loss: -2.862415640382668e+22, val_recall@10: 0.00918, val_precision@10: 0.00904, val_ndcg@10: 0.0119
2024-12-11 00:06:19,102 [Iteration 1800/5000] train_loss: -2.7913152864455376e+22, val_loss: -3.4136524067131334e+22, val_recall@10: 0.00813, val_precision@10: 0.00868, val_ndcg@10: 0.0119
2024-12-11 00:06:31,101 [Iteration 2000/5000] train_loss: -1.1711956707428357e+23, val_loss: -3.2720216293717165e+22, val_recall@10: 0.01008, val_precision@10: 0.00904, val_ndcg@10: 0.01197
2024-12-11 00:06:42,389 [Iteration 2200/5000] train_loss: -7.4326503026597565e+22, val_loss: -4.2549068027074326e+22, val_recall@10: 0.01192, val_precision@10: 0.0094, val_ndcg@10: 0.01264
2024-12-11 00:06:53,102 [Iteration 2400/5000] train_loss: -9.607984849351769e+22, val_loss: -4.139848389067408e+22, val_recall@10: 0.01038, val_precision@10: 0.0094, val_ndcg@10: 0.01236
2024-12-11 00:07:05,756 [Iteration 2600/5000] train_loss: -6.518111982448996e+22, val_loss: -4.431342974229038e+22, val_recall@10: 0.01036, val_precision@10: 0.0094, val_ndcg@10: 0.01254
2024-12-11 00:07:18,201 [Iteration 2800/5000] train_loss: -2.6651696860628714e+22, val_loss: -4.997176582491756e+22, val_recall@10: 0.01092, val_precision@10: 0.00995, val_ndcg@10: 0.01331
2024-12-11 00:08:20,946 [Iteration 3000/5000] train_loss: -4.895048904101838e+22, val_loss: -5.747562299164563e+22, val_recall@10: 0.01082, val_precision@10: 0.00958, val_ndcg@10: 0.01276
2024-12-11 00:10:33,076 [Iteration 3200/5000] train_loss: -4.331879625378673e+22, val_loss: -5.875582522892122e+22, val_recall@10: 0.01089, val_precision@10: 0.00976, val_ndcg@10: 0.01272
2024-12-11 00:12:21,195 [Iteration 3400/5000] train_loss: -1.2023895833458398e+23, val_loss: -5.9011427025772635e+22, val_recall@10: 0.01066, val_precision@10: 0.0094, val_ndcg@10: 0.01214
2024-12-11 00:14:23,872 [Iteration 3600/5000] train_loss: -5.435254778685003e+22, val_loss: -6.587414274234899e+22, val_recall@10: 0.01066, val_precision@10: 0.0094, val_ndcg@10: 0.01228
2024-12-11 00:16:25,481 [Iteration 3800/5000] train_loss: -1.2122917379185318e+23, val_loss: -5.634016644639373e+22, val_recall@10: 0.01046, val_precision@10: 0.00886, val_ndcg@10: 0.01248
2024-12-11 00:16:47,916 [Iteration 4000/5000] train_loss: -1.0366362203563345e+23, val_loss: -6.239919229146768e+22, val_recall@10: 0.01088, val_precision@10: 0.00922, val_ndcg@10: 0.01218
2024-12-11 00:19:03,196 [Iteration 4200/5000] train_loss: -3.1678288253726677e+22, val_loss: -6.994230733614754e+22, val_recall@10: 0.01072, val_precision@10: 0.00904, val_ndcg@10: 0.01198
2024-12-11 00:21:06,139 [Iteration 4400/5000] train_loss: -3.225012561065264e+23, val_loss: -5.66313691982995e+22, val_recall@10: 0.01072, val_precision@10: 0.00904, val_ndcg@10: 0.01198
2024-12-11 00:22:55,769 [Iteration 4600/5000] train_loss: -4.41774390479423e+22, val_loss: -7.365130085246404e+22, val_recall@10: 0.01072, val_precision@10: 0.00904, val_ndcg@10: 0.01197
2024-12-11 00:23:06,959 [Iteration 4800/5000] train_loss: -7.66483473252873e+22, val_loss: -5.691909066769332e+22, val_recall@10: 0.01048, val_precision@10: 0.00868, val_ndcg@10: 0.01225
2024-12-11 00:23:18,004 [Iteration 4999/5000] train_loss: -1.949667050663825e+22, val_loss: -7.242281344970955e+22, val_recall@10: 0.01099, val_precision@10: 0.00904, val_ndcg@10: 0.01255
2024-12-11 00:23:18,145 Experiment batch_512: best train loss -3.225012561065264e+23; best val loss -3.225012561065264e+23; last train loss -1.949667050663825e+22; last val loss -1.949667050663825e+22
2024-12-11 00:23:18,145 Experiment setup: {'batch_size': 2048, 'LR': 0.001, 'K': 10, 'name': 'batch_2048'}
2024-12-11 00:23:25,483 [Iteration 0/5000] train_loss: -0.60611, val_loss: -0.18911, val_recall@10: 0.00229, val_precision@10: 0.00127, val_ndcg@10: 0.00159
2024-12-11 00:23:36,898 [Iteration 200/5000] train_loss: -1098421305344.0, val_loss: -478404476928.0, val_recall@10: 0.00592, val_precision@10: 0.00344, val_ndcg@10: 0.00579
2024-12-11 00:23:48,135 [Iteration 400/5000] train_loss: -3.308676228826792e+18, val_loss: -3.7676648839407206e+17, val_recall@10: 0.01155, val_precision@10: 0.00796, val_ndcg@10: 0.01151
2024-12-11 00:23:59,141 [Iteration 600/5000] train_loss: -2.0556083772182002e+21, val_loss: -1.8557412997677764e+21, val_recall@10: 0.02214, val_precision@10: 0.01212, val_ndcg@10: 0.01884
2024-12-11 00:24:10,518 [Iteration 800/5000] train_loss: -2.2160065549267955e+22, val_loss: -1.8216102351892933e+22, val_recall@10: 0.02442, val_precision@10: 0.01338, val_ndcg@10: 0.02041
2024-12-11 00:24:21,750 [Iteration 1000/5000] train_loss: -4.450276107062504e+22, val_loss: -2.4847262115928314e+22, val_recall@10: 0.02355, val_precision@10: 0.01284, val_ndcg@10: 0.01956
2024-12-11 00:24:32,965 [Iteration 1200/5000] train_loss: -1.4929117512759278e+23, val_loss: -3.881100827876278e+22, val_recall@10: 0.02461, val_precision@10: 0.01193, val_ndcg@10: 0.01947
2024-12-11 00:24:44,186 [Iteration 1400/5000] train_loss: -4.446478671856705e+22, val_loss: -4.643463867758077e+22, val_recall@10: 0.02497, val_precision@10: 0.0123, val_ndcg@10: 0.01978
2024-12-11 00:24:54,386 [Iteration 1600/5000] train_loss: -4.628241701017565e+22, val_loss: -5.435832140157232e+22, val_recall@10: 0.02475, val_precision@10: 0.01212, val_ndcg@10: 0.01935
2024-12-11 00:25:06,064 [Iteration 1800/5000] train_loss: -7.70954556890934e+22, val_loss: -4.7321883832969775e+22, val_recall@10: 0.02444, val_precision@10: 0.01157, val_ndcg@10: 0.01921
2024-12-11 00:25:18,140 [Iteration 2000/5000] train_loss: -4.3780685431569845e+22, val_loss: -6.884169063761298e+22, val_recall@10: 0.02232, val_precision@10: 0.01103, val_ndcg@10: 0.0182
2024-12-11 00:26:52,445 [Iteration 2200/5000] train_loss: -2.1152924663879166e+23, val_loss: -7.1237375955793084e+22, val_recall@10: 0.02096, val_precision@10: 0.01121, val_ndcg@10: 0.01803
2024-12-11 00:28:26,106 [Iteration 2400/5000] train_loss: -4.274803255501193e+22, val_loss: -8.284331882871307e+22, val_recall@10: 0.02067, val_precision@10: 0.01085, val_ndcg@10: 0.01758
2024-12-11 00:30:10,552 [Iteration 2600/5000] train_loss: -5.823239886582971e+22, val_loss: -8.936609834181587e+22, val_recall@10: 0.02053, val_precision@10: 0.01067, val_ndcg@10: 0.01749
2024-12-11 00:31:40,614 [Iteration 2800/5000] train_loss: -1.005388264557802e+23, val_loss: -9.196624257947897e+22, val_recall@10: 0.02002, val_precision@10: 0.01049, val_ndcg@10: 0.01746
2024-12-11 00:33:14,443 [Iteration 3000/5000] train_loss: -2.2518439489615962e+23, val_loss: -9.69480073936859e+22, val_recall@10: 0.02006, val_precision@10: 0.01067, val_ndcg@10: 0.01809
2024-12-11 00:33:35,212 [Iteration 3200/5000] train_loss: -8.092288486841048e+22, val_loss: -1.080281414993115e+23, val_recall@10: 0.02238, val_precision@10: 0.01103, val_ndcg@10: 0.01823
2024-12-11 00:33:46,278 [Iteration 3400/5000] train_loss: -5.115422643948033e+22, val_loss: -1.1289752348841702e+23, val_recall@10: 0.02066, val_precision@10: 0.01103, val_ndcg@10: 0.01781
2024-12-11 00:33:56,862 [Iteration 3600/5000] train_loss: -2.1346343459235623e+23, val_loss: -1.0267214557046858e+23, val_recall@10: 0.02062, val_precision@10: 0.01121, val_ndcg@10: 0.01747
2024-12-11 00:36:06,041 [Iteration 3800/5000] train_loss: -8.008772834631164e+22, val_loss: -1.2301606701600498e+23, val_recall@10: 0.02246, val_precision@10: 0.01157, val_ndcg@10: 0.01819
2024-12-11 00:38:15,201 [Iteration 4000/5000] train_loss: -1.681620682142081e+23, val_loss: -1.2260717619863675e+23, val_recall@10: 0.02244, val_precision@10: 0.01139, val_ndcg@10: 0.01804
2024-12-11 00:40:09,174 [Iteration 4200/5000] train_loss: -9.125201671457428e+22, val_loss: -1.1882853001048334e+23, val_recall@10: 0.02037, val_precision@10: 0.01103, val_ndcg@10: 0.01828
2024-12-11 00:40:35,020 [Iteration 4400/5000] train_loss: -1.3619730148458475e+23, val_loss: -1.3471800411498236e+23, val_recall@10: 0.02037, val_precision@10: 0.01103, val_ndcg@10: 0.01827
2024-12-11 00:40:44,337 [Iteration 4600/5000] train_loss: -3.061158996542569e+23, val_loss: -1.2683402962890533e+23, val_recall@10: 0.02042, val_precision@10: 0.01121, val_ndcg@10: 0.01838
2024-12-11 00:40:53,650 [Iteration 4800/5000] train_loss: -7.953582121917664e+22, val_loss: -8.885526404328249e+22, val_recall@10: 0.02038, val_precision@10: 0.01121, val_ndcg@10: 0.01841
2024-12-11 00:41:02,424 [Iteration 4999/5000] train_loss: -1.959394780822949e+23, val_loss: -1.4430414110182183e+23, val_recall@10: 0.02188, val_precision@10: 0.01157, val_ndcg@10: 0.01881
2024-12-11 00:41:02,558 Experiment batch_2048: best train loss -3.061158996542569e+23; best val loss -3.061158996542569e+23; last train loss -1.959394780822949e+23; last val loss -1.959394780822949e+23
2024-12-11 00:41:02,559 Experiment setup: {'batch_size': 1024, 'LR': 0.01, 'K': 10, 'name': 'LR_1e-2'}
2024-12-11 00:41:09,243 [Iteration 0/5000] train_loss: -0.99124, val_loss: -3.90769, val_recall@10: 0.00019, val_precision@10: 0.00054, val_ndcg@10: 0.00046
2024-12-11 00:41:17,596 [Iteration 200/5000] train_loss: -1.413277661512882e+23, val_loss: -8.712002710685664e+22, val_recall@10: 0.03092, val_precision@10: 0.01808, val_ndcg@10: 0.02733
2024-12-11 00:41:26,142 [Iteration 400/5000] train_loss: -4.095162412556743e+23, val_loss: -3.012754307747591e+23, val_recall@10: 0.015, val_precision@10: 0.01302, val_ndcg@10: 0.0183
2024-12-11 00:41:34,625 [Iteration 600/5000] train_loss: -2.3425356368177323e+23, val_loss: -6.366001644026662e+23, val_recall@10: 0.01637, val_precision@10: 0.0123, val_ndcg@10: 0.01731
2024-12-11 00:41:43,067 [Iteration 800/5000] train_loss: -2.0299795176387416e+23, val_loss: -1.0272372799916063e+24, val_recall@10: 0.01629, val_precision@10: 0.01139, val_ndcg@10: 0.01683
2024-12-11 00:41:51,419 [Iteration 1000/5000] train_loss: -6.928721013147053e+23, val_loss: -1.7452957442079826e+24, val_recall@10: 0.01441, val_precision@10: 0.01013, val_ndcg@10: 0.01582
2024-12-11 00:41:59,860 [Iteration 1200/5000] train_loss: -8.024581550187145e+23, val_loss: -2.4907416425935124e+24, val_recall@10: 0.01683, val_precision@10: 0.01193, val_ndcg@10: 0.01599
2024-12-11 00:42:08,399 [Iteration 1400/5000] train_loss: -3.523895211343603e+23, val_loss: -3.2801983018047756e+24, val_recall@10: 0.01576, val_precision@10: 0.01103, val_ndcg@10: 0.01418
2024-12-11 00:42:16,985 [Iteration 1600/5000] train_loss: -2.80582075034135e+23, val_loss: -3.972267393291522e+24, val_recall@10: 0.01327, val_precision@10: 0.00922, val_ndcg@10: 0.01255
2024-12-11 00:42:25,761 [Iteration 1800/5000] train_loss: -5.8943764044251095e+23, val_loss: -4.849274317489244e+24, val_recall@10: 0.01615, val_precision@10: 0.0094, val_ndcg@10: 0.01336
2024-12-11 00:42:34,037 [Iteration 2000/5000] train_loss: -4.134881639254359e+23, val_loss: -2.303770200463599e+24, val_recall@10: 0.01678, val_precision@10: 0.00958, val_ndcg@10: 0.01364
2024-12-11 00:42:42,105 [Iteration 2200/5000] train_loss: -5.017792170074014e+23, val_loss: -6.536766324451129e+24, val_recall@10: 0.0168, val_precision@10: 0.0094, val_ndcg@10: 0.01365
2024-12-11 00:42:50,293 [Iteration 2400/5000] train_loss: -2.344828329316034e+23, val_loss: -4.432206692579974e+24, val_recall@10: 0.01753, val_precision@10: 0.00976, val_ndcg@10: 0.01425
2024-12-11 00:42:58,500 [Iteration 2600/5000] train_loss: -6.556908151366987e+23, val_loss: -4.0240220396333235e+24, val_recall@10: 0.01613, val_precision@10: 0.00958, val_ndcg@10: 0.01361
2024-12-11 00:43:06,749 [Iteration 2800/5000] train_loss: -4.2332380933883096e+23, val_loss: -9.535264397506286e+24, val_recall@10: 0.01624, val_precision@10: 0.01031, val_ndcg@10: 0.01447
2024-12-11 00:43:14,940 [Iteration 3000/5000] train_loss: -7.441174445818466e+23, val_loss: -1.0645021097441405e+25, val_recall@10: 0.01686, val_precision@10: 0.01067, val_ndcg@10: 0.01447
2024-12-11 00:43:23,143 [Iteration 3200/5000] train_loss: -3.537439156718972e+23, val_loss: -1.1593137625969892e+25, val_recall@10: 0.01905, val_precision@10: 0.01103, val_ndcg@10: 0.01522
2024-12-11 00:43:31,316 [Iteration 3400/5000] train_loss: -2.4685858059242946e+23, val_loss: -1.222797079405156e+25, val_recall@10: 0.01616, val_precision@10: 0.01085, val_ndcg@10: 0.0144
2024-12-11 00:43:39,666 [Iteration 3600/5000] train_loss: -5.4394407844666515e+23, val_loss: -1.3332575664243343e+25, val_recall@10: 0.01466, val_precision@10: 0.01049, val_ndcg@10: 0.01379
2024-12-11 00:43:47,888 [Iteration 3800/5000] train_loss: -8.558518233945026e+23, val_loss: -1.2851425779804263e+25, val_recall@10: 0.01445, val_precision@10: 0.01049, val_ndcg@10: 0.01359
2024-12-11 00:43:55,988 [Iteration 4000/5000] train_loss: -6.608245584239309e+23, val_loss: -1.4204824193161176e+25, val_recall@10: 0.01409, val_precision@10: 0.00995, val_ndcg@10: 0.01303
2024-12-11 00:44:04,156 [Iteration 4200/5000] train_loss: -8.76659822767241e+23, val_loss: -1.007268665120297e+25, val_recall@10: 0.01224, val_precision@10: 0.00976, val_ndcg@10: 0.01243
2024-12-11 00:44:12,351 [Iteration 4400/5000] train_loss: -3.970003776032415e+23, val_loss: -1.7055720067049794e+25, val_recall@10: 0.01185, val_precision@10: 0.00995, val_ndcg@10: 0.01226
2024-12-11 00:44:20,640 [Iteration 4600/5000] train_loss: -6.912135516727343e+23, val_loss: -9.223890851531849e+24, val_recall@10: 0.01135, val_precision@10: 0.0094, val_ndcg@10: 0.01173
2024-12-11 00:44:28,739 [Iteration 4800/5000] train_loss: -7.643166293425585e+23, val_loss: -1.8349351029607888e+25, val_recall@10: 0.01132, val_precision@10: 0.00922, val_ndcg@10: 0.01148
2024-12-11 00:44:36,864 [Iteration 4999/5000] train_loss: -5.88991279676243e+23, val_loss: -1.9282955735157889e+25, val_recall@10: 0.01023, val_precision@10: 0.00922, val_ndcg@10: 0.01127
2024-12-11 00:44:36,997 Experiment LR_1e-2: best train loss -8.76659822767241e+23; best val loss -8.76659822767241e+23; last train loss -5.88991279676243e+23; last val loss -5.88991279676243e+23
2024-12-11 00:44:36,997 Experiment setup: {'batch_size': 1024, 'LR': 0.001, 'K': 10, 'name': 'LR_1e-3'}
2024-12-11 00:44:43,790 [Iteration 0/5000] train_loss: -0.98129, val_loss: -0.45998, val_recall@10: 0.00042, val_precision@10: 0.0009, val_ndcg@10: 0.00071
2024-12-11 00:44:52,017 [Iteration 200/5000] train_loss: -74042687488.0, val_loss: -43830788096.0, val_recall@10: 0.00297, val_precision@10: 0.00181, val_ndcg@10: 0.00241
2024-12-11 00:45:00,069 [Iteration 400/5000] train_loss: -7.450809621859533e+16, val_loss: -4.554257907633357e+16, val_recall@10: 0.01105, val_precision@10: 0.0094, val_ndcg@10: 0.01051
2024-12-11 00:45:08,249 [Iteration 600/5000] train_loss: -4.605196612839324e+20, val_loss: -1.810958630973111e+20, val_recall@10: 0.01938, val_precision@10: 0.01356, val_ndcg@10: 0.01618
2024-12-11 00:45:16,382 [Iteration 800/5000] train_loss: -6.235499396472467e+21, val_loss: -5.441783872244784e+21, val_recall@10: 0.01791, val_precision@10: 0.0123, val_ndcg@10: 0.01494
2024-12-11 00:45:24,541 [Iteration 1000/5000] train_loss: -4.956237961159032e+22, val_loss: -1.1808059920596741e+22, val_recall@10: 0.02053, val_precision@10: 0.01374, val_ndcg@10: 0.01696
2024-12-11 00:45:32,988 [Iteration 1200/5000] train_loss: -2.8074908652271642e+22, val_loss: -1.798048077478835e+22, val_recall@10: 0.02044, val_precision@10: 0.01338, val_ndcg@10: 0.01717
2024-12-11 00:45:41,184 [Iteration 1400/5000] train_loss: -4.374069797047842e+22, val_loss: -2.1548710907051665e+22, val_recall@10: 0.02095, val_precision@10: 0.01447, val_ndcg@10: 0.01802
2024-12-11 00:45:49,342 [Iteration 1600/5000] train_loss: -3.2527320366277445e+22, val_loss: -2.402002292197439e+22, val_recall@10: 0.02168, val_precision@10: 0.01483, val_ndcg@10: 0.0189
2024-12-11 00:45:57,446 [Iteration 1800/5000] train_loss: -6.709361844224912e+22, val_loss: -2.61010710075877e+22, val_recall@10: 0.02099, val_precision@10: 0.01483, val_ndcg@10: 0.01885
2024-12-11 00:46:05,505 [Iteration 2000/5000] train_loss: -5.586686064355522e+22, val_loss: -2.7390512379498844e+22, val_recall@10: 0.02066, val_precision@10: 0.01501, val_ndcg@10: 0.01962
2024-12-11 00:46:13,801 [Iteration 2200/5000] train_loss: -3.430908399045366e+22, val_loss: -3.204792794854255e+22, val_recall@10: 0.01987, val_precision@10: 0.01429, val_ndcg@10: 0.01903
2024-12-11 00:46:21,909 [Iteration 2400/5000] train_loss: -9.16273557147186e+22, val_loss: -3.6446740071583205e+22, val_recall@10: 0.01984, val_precision@10: 0.01447, val_ndcg@10: 0.01893
2024-12-11 00:46:30,022 [Iteration 2600/5000] train_loss: -3.997061312521664e+22, val_loss: -3.932117604455131e+22, val_recall@10: 0.02008, val_precision@10: 0.01429, val_ndcg@10: 0.01899
2024-12-11 00:46:38,288 [Iteration 2800/5000] train_loss: -1.7288511699242128e+22, val_loss: -3.5953478818795824e+22, val_recall@10: 0.0192, val_precision@10: 0.01356, val_ndcg@10: 0.01881
2024-12-11 00:46:46,550 [Iteration 3000/5000] train_loss: -1.4685315146931577e+23, val_loss: -4.391456393769269e+22, val_recall@10: 0.01917, val_precision@10: 0.01338, val_ndcg@10: 0.01856
2024-12-11 00:46:55,215 [Iteration 3200/5000] train_loss: -8.89505692185969e+22, val_loss: -3.889011850981717e+22, val_recall@10: 0.01888, val_precision@10: 0.01338, val_ndcg@10: 0.01895
2024-12-11 00:47:03,477 [Iteration 3400/5000] train_loss: -9.439606180513483e+21, val_loss: -4.4532381245374254e+22, val_recall@10: 0.01901, val_precision@10: 0.01356, val_ndcg@10: 0.01907
2024-12-11 00:47:11,703 [Iteration 3600/5000] train_loss: -8.3493908830883e+22, val_loss: -4.614051759311646e+22, val_recall@10: 0.01911, val_precision@10: 0.01338, val_ndcg@10: 0.01902
2024-12-11 00:47:19,873 [Iteration 3800/5000] train_loss: -2.8683130590587134e+23, val_loss: -5.445480651998911e+22, val_recall@10: 0.01748, val_precision@10: 0.01284, val_ndcg@10: 0.01857
2024-12-11 00:47:28,157 [Iteration 4000/5000] train_loss: -6.16652226457966e+22, val_loss: -3.955672331226204e+22, val_recall@10: 0.01747, val_precision@10: 0.01284, val_ndcg@10: 0.01846
2024-12-11 00:47:36,232 [Iteration 4200/5000] train_loss: -7.0611290039195665e+22, val_loss: -5.133461361895502e+22, val_recall@10: 0.01852, val_precision@10: 0.0132, val_ndcg@10: 0.01879
2024-12-11 00:47:44,404 [Iteration 4400/5000] train_loss: -1.9118279417026468e+23, val_loss: -4.948014388239454e+22, val_recall@10: 0.01747, val_precision@10: 0.01284, val_ndcg@10: 0.01837
2024-12-11 00:47:52,573 [Iteration 4600/5000] train_loss: -7.334653325848063e+22, val_loss: -5.597968482142011e+22, val_recall@10: 0.0189, val_precision@10: 0.0132, val_ndcg@10: 0.01897
2024-12-11 00:48:00,688 [Iteration 4800/5000] train_loss: -8.591148614685176e+22, val_loss: -6.214490104210783e+22, val_recall@10: 0.01819, val_precision@10: 0.01302, val_ndcg@10: 0.01874
2024-12-11 00:48:09,136 [Iteration 4999/5000] train_loss: -9.491347023322426e+22, val_loss: -4.465217699546231e+22, val_recall@10: 0.01753, val_precision@10: 0.0123, val_ndcg@10: 0.01813
2024-12-11 00:48:09,259 Experiment LR_1e-3: best train loss -2.8683130590587134e+23; best val loss -2.8683130590587134e+23; last train loss -9.491347023322426e+22; last val loss -9.491347023322426e+22
2024-12-11 00:48:09,260 Experiment setup: {'batch_size': 1024, 'LR': 0.0001, 'K': 10, 'name': 'LR_1e-4'}
2024-12-11 00:48:16,219 [Iteration 0/5000] train_loss: -1.41177, val_loss: -0.74829, val_recall@10: 0.00153, val_precision@10: 0.00108, val_ndcg@10: 0.00117
2024-12-11 00:48:24,391 [Iteration 200/5000] train_loss: -96.5496, val_loss: -142.34026, val_recall@10: 0.00153, val_precision@10: 0.00108, val_ndcg@10: 0.0013
2024-12-11 00:48:32,554 [Iteration 400/5000] train_loss: -11918.20898, val_loss: -13542.94336, val_recall@10: 0.00161, val_precision@10: 0.00145, val_ndcg@10: 0.00158
2024-12-11 00:48:40,674 [Iteration 600/5000] train_loss: -230226.73438, val_loss: -416866.1875, val_recall@10: 0.00173, val_precision@10: 0.00181, val_ndcg@10: 0.00221
2024-12-11 00:48:48,814 [Iteration 800/5000] train_loss: -3675727.75, val_loss: -5733159.5, val_recall@10: 0.00177, val_precision@10: 0.00199, val_ndcg@10: 0.00247
2024-12-11 00:48:57,108 [Iteration 1000/5000] train_loss: -71135624.0, val_loss: -31823232.0, val_recall@10: 0.00177, val_precision@10: 0.00199, val_ndcg@10: 0.00255
2024-12-11 00:49:05,189 [Iteration 1200/5000] train_loss: -388865888.0, val_loss: -315874336.0, val_recall@10: 0.00177, val_precision@10: 0.00199, val_ndcg@10: 0.00275
2024-12-11 00:49:13,365 [Iteration 1400/5000] train_loss: -1256524288.0, val_loss: -1737294848.0, val_recall@10: 0.00176, val_precision@10: 0.00199, val_ndcg@10: 0.00281
2024-12-11 00:49:21,542 [Iteration 1600/5000] train_loss: -4278228224.0, val_loss: -5564786176.0, val_recall@10: 0.00176, val_precision@10: 0.00199, val_ndcg@10: 0.00319
2024-12-11 00:49:29,638 [Iteration 1800/5000] train_loss: -35597238272.0, val_loss: -20117225472.0, val_recall@10: 0.00176, val_precision@10: 0.00199, val_ndcg@10: 0.00321
2024-12-11 00:49:37,785 [Iteration 2000/5000] train_loss: -206508490752.0, val_loss: -56551837696.0, val_recall@10: 0.00226, val_precision@10: 0.00253, val_ndcg@10: 0.00374
2024-12-11 00:49:46,119 [Iteration 2200/5000] train_loss: -56200175616.0, val_loss: -128127574016.0, val_recall@10: 0.00226, val_precision@10: 0.00253, val_ndcg@10: 0.00375
2024-12-11 00:49:54,231 [Iteration 2400/5000] train_loss: -627582500864.0, val_loss: -145488691200.0, val_recall@10: 0.00229, val_precision@10: 0.00271, val_ndcg@10: 0.00397
2024-12-11 00:50:02,548 [Iteration 2600/5000] train_loss: -350660296704.0, val_loss: -604134506496.0, val_recall@10: 0.00515, val_precision@10: 0.00325, val_ndcg@10: 0.00515
2024-12-11 00:50:10,730 [Iteration 2800/5000] train_loss: -2414196555776.0, val_loss: -1008572891136.0, val_recall@10: 0.00539, val_precision@10: 0.00362, val_ndcg@10: 0.0055
2024-12-11 00:50:18,846 [Iteration 3000/5000] train_loss: -15505878417408.0, val_loss: -944444080128.0, val_recall@10: 0.00539, val_precision@10: 0.00362, val_ndcg@10: 0.00555
2024-12-11 00:50:26,939 [Iteration 3200/5000] train_loss: -2758023053312.0, val_loss: -2099619692544.0, val_recall@10: 0.0066, val_precision@10: 0.00398, val_ndcg@10: 0.00617
2024-12-11 00:50:35,139 [Iteration 3400/5000] train_loss: -16788600389632.0, val_loss: -4170303930368.0, val_recall@10: 0.00667, val_precision@10: 0.00416, val_ndcg@10: 0.00637
2024-12-11 00:50:43,284 [Iteration 3600/5000] train_loss: -3932172582912.0, val_loss: -6063997321216.0, val_recall@10: 0.00672, val_precision@10: 0.00434, val_ndcg@10: 0.00657
2024-12-11 00:50:51,457 [Iteration 3800/5000] train_loss: -118426190217216.0, val_loss: -8775415627776.0, val_recall@10: 0.00684, val_precision@10: 0.00452, val_ndcg@10: 0.0067
2024-12-11 00:51:00,093 [Iteration 4000/5000] train_loss: -123952991043584.0, val_loss: -7872379355136.0, val_recall@10: 0.0069, val_precision@10: 0.0047, val_ndcg@10: 0.00685
2024-12-11 00:51:08,221 [Iteration 4200/5000] train_loss: -18142923325440.0, val_loss: -17078292578304.0, val_recall@10: 0.00697, val_precision@10: 0.00488, val_ndcg@10: 0.00708
2024-12-11 00:51:16,657 [Iteration 4400/5000] train_loss: -47695569879040.0, val_loss: -8683295604736.0, val_recall@10: 0.00721, val_precision@10: 0.00506, val_ndcg@10: 0.00749
2024-12-11 00:51:24,877 [Iteration 4600/5000] train_loss: -201850930331648.0, val_loss: -24197627641856.0, val_recall@10: 0.00726, val_precision@10: 0.00524, val_ndcg@10: 0.00767
2024-12-11 00:51:32,962 [Iteration 4800/5000] train_loss: -348053143814144.0, val_loss: -31326373675008.0, val_recall@10: 0.00726, val_precision@10: 0.00524, val_ndcg@10: 0.00769
2024-12-11 00:51:41,141 [Iteration 4999/5000] train_loss: -383707579940864.0, val_loss: -34762790010880.0, val_recall@10: 0.00726, val_precision@10: 0.00524, val_ndcg@10: 0.00774
2024-12-11 00:51:41,273 Experiment LR_1e-4: best train loss -383707579940864.0; best val loss -383707579940864.0; last train loss -383707579940864.0; last val loss -383707579940864.0
2024-12-11 00:51:41,273 Experiment setup: {'batch_size': 1024, 'LR': 0.001, 'K': 10, 'name': 'K_10'}
2024-12-11 00:51:48,104 [Iteration 0/5000] train_loss: -1.09733, val_loss: -0.7409, val_recall@10: 0.00071, val_precision@10: 0.00072, val_ndcg@10: 0.00109
2024-12-11 00:51:56,162 [Iteration 200/5000] train_loss: -1512205713408.0, val_loss: -163287810048.0, val_recall@10: 0.00281, val_precision@10: 0.00271, val_ndcg@10: 0.00347
2024-12-11 00:52:04,351 [Iteration 400/5000] train_loss: -1.567788819682427e+17, val_loss: -8.432426115347251e+16, val_recall@10: 0.01084, val_precision@10: 0.00868, val_ndcg@10: 0.01069
2024-12-11 00:52:12,520 [Iteration 600/5000] train_loss: -2.8912726098062816e+20, val_loss: -3.583127899093168e+20, val_recall@10: 0.00962, val_precision@10: 0.0094, val_ndcg@10: 0.01174
2024-12-11 00:52:20,806 [Iteration 800/5000] train_loss: -3.3411786800696364e+22, val_loss: -1.6850475836885378e+22, val_recall@10: 0.01114, val_precision@10: 0.01103, val_ndcg@10: 0.01336
2024-12-11 00:52:28,950 [Iteration 1000/5000] train_loss: -4.597072738356496e+22, val_loss: -3.4587287102035033e+22, val_recall@10: 0.0138, val_precision@10: 0.0132, val_ndcg@10: 0.01474
2024-12-11 00:52:37,120 [Iteration 1200/5000] train_loss: -6.645970526949933e+22, val_loss: -3.4582864567200955e+22, val_recall@10: 0.01381, val_precision@10: 0.01284, val_ndcg@10: 0.01521
2024-12-11 00:52:45,305 [Iteration 1400/5000] train_loss: -4.154472477777406e+22, val_loss: -5.1571944312118194e+22, val_recall@10: 0.01514, val_precision@10: 0.01284, val_ndcg@10: 0.01536
2024-12-11 00:52:53,471 [Iteration 1600/5000] train_loss: -5.32157536725088e+22, val_loss: -5.6039807876445506e+22, val_recall@10: 0.01375, val_precision@10: 0.01175, val_ndcg@10: 0.01542
2024-12-11 00:53:01,626 [Iteration 1800/5000] train_loss: -5.598012617418359e+22, val_loss: -5.853911201485215e+22, val_recall@10: 0.0127, val_precision@10: 0.01085, val_ndcg@10: 0.01486
2024-12-11 00:53:09,754 [Iteration 2000/5000] train_loss: -5.329464322718145e+22, val_loss: -6.872617330717092e+22, val_recall@10: 0.01282, val_precision@10: 0.01067, val_ndcg@10: 0.01494
2024-12-11 00:53:17,931 [Iteration 2200/5000] train_loss: -7.496632041845884e+22, val_loss: -5.63688588796197e+22, val_recall@10: 0.01398, val_precision@10: 0.01103, val_ndcg@10: 0.01547
2024-12-11 00:53:26,138 [Iteration 2400/5000] train_loss: -7.836370537295794e+22, val_loss: -7.674452619892943e+22, val_recall@10: 0.01451, val_precision@10: 0.01139, val_ndcg@10: 0.01584
2024-12-11 00:53:34,365 [Iteration 2600/5000] train_loss: -8.056710950504747e+22, val_loss: -8.017174750095987e+22, val_recall@10: 0.01425, val_precision@10: 0.01121, val_ndcg@10: 0.01559
2024-12-11 00:53:42,799 [Iteration 2800/5000] train_loss: -7.453881622383069e+22, val_loss: -9.046735455149752e+22, val_recall@10: 0.01418, val_precision@10: 0.01103, val_ndcg@10: 0.01567
2024-12-11 00:53:50,992 [Iteration 3000/5000] train_loss: -9.17464849320618e+22, val_loss: -8.793861038232675e+22, val_recall@10: 0.01379, val_precision@10: 0.01067, val_ndcg@10: 0.01545
2024-12-11 00:53:59,160 [Iteration 3200/5000] train_loss: -1.7666342315880283e+23, val_loss: -9.189548202213372e+22, val_recall@10: 0.01425, val_precision@10: 0.01103, val_ndcg@10: 0.01579
2024-12-11 00:54:07,363 [Iteration 3400/5000] train_loss: -8.846091084551142e+22, val_loss: -1.0348404550409168e+23, val_recall@10: 0.01354, val_precision@10: 0.01067, val_ndcg@10: 0.01508
2024-12-11 00:54:15,412 [Iteration 3600/5000] train_loss: -1.6178934864068927e+23, val_loss: -1.0856415992696113e+23, val_recall@10: 0.01354, val_precision@10: 0.01067, val_ndcg@10: 0.01539
2024-12-11 00:54:23,464 [Iteration 3800/5000] train_loss: -7.043791046074116e+22, val_loss: -1.0954380993950452e+23, val_recall@10: 0.01392, val_precision@10: 0.01085, val_ndcg@10: 0.01534
2024-12-11 00:54:31,599 [Iteration 4000/5000] train_loss: -1.4126998496806903e+23, val_loss: -1.036989392639113e+23, val_recall@10: 0.01356, val_precision@10: 0.01049, val_ndcg@10: 0.01505
2024-12-11 00:54:39,839 [Iteration 4200/5000] train_loss: -1.7282765331297585e+23, val_loss: -1.190897658104686e+23, val_recall@10: 0.0135, val_precision@10: 0.01031, val_ndcg@10: 0.01518
2024-12-11 00:54:48,034 [Iteration 4400/5000] train_loss: -2.5992237018992666e+23, val_loss: -1.2437409145484153e+23, val_recall@10: 0.0136, val_precision@10: 0.01031, val_ndcg@10: 0.01509
2024-12-11 00:54:56,146 [Iteration 4600/5000] train_loss: -4.267606503296655e+22, val_loss: -1.1616176852713218e+23, val_recall@10: 0.0136, val_precision@10: 0.01031, val_ndcg@10: 0.01492
2024-12-11 00:55:04,257 [Iteration 4800/5000] train_loss: -1.0037546288289696e+23, val_loss: -9.487314500216078e+22, val_recall@10: 0.01344, val_precision@10: 0.01013, val_ndcg@10: 0.01492
2024-12-11 00:55:12,548 [Iteration 4999/5000] train_loss: -1.053653251692339e+23, val_loss: -1.291500687876754e+23, val_recall@10: 0.01371, val_precision@10: 0.01049, val_ndcg@10: 0.01508
2024-12-11 00:55:12,676 Experiment K_10: best train loss -2.5992237018992666e+23; best val loss -2.5992237018992666e+23; last train loss -1.053653251692339e+23; last val loss -1.053653251692339e+23
2024-12-11 00:55:12,676 Experiment setup: {'batch_size': 1024, 'LR': 0.001, 'K': 50, 'name': 'K_50'}
2024-12-11 00:55:31,155 [Iteration 0/5000] train_loss: -1.66196, val_loss: -1.61597, val_recall@10: 0.00648, val_precision@10: 0.00076, val_ndcg@10: 0.00263
2024-12-11 00:55:49,856 [Iteration 200/5000] train_loss: -94976393216.0, val_loss: -77065592832.0, val_recall@10: 0.01102, val_precision@10: 0.00221, val_ndcg@10: 0.00608
2024-12-11 00:56:08,456 [Iteration 400/5000] train_loss: -8.18064654252114e+16, val_loss: -8.631075224734925e+16, val_recall@10: 0.04519, val_precision@10: 0.00763, val_ndcg@10: 0.02219
2024-12-11 00:56:26,911 [Iteration 600/5000] train_loss: -1.3832554335364322e+21, val_loss: -4.107302211566541e+20, val_recall@10: 0.07932, val_precision@10: 0.0119, val_ndcg@10: 0.03671
2024-12-11 00:56:45,582 [Iteration 800/5000] train_loss: -1.0687965153673798e+22, val_loss: -1.2113969177085696e+22, val_recall@10: 0.07918, val_precision@10: 0.0119, val_ndcg@10: 0.03769
2024-12-11 00:57:04,137 [Iteration 1000/5000] train_loss: -1.697822832161509e+22, val_loss: -1.8978977225872383e+22, val_recall@10: 0.07779, val_precision@10: 0.01165, val_ndcg@10: 0.03769
2024-12-11 00:57:22,708 [Iteration 1200/5000] train_loss: -1.016795161837991e+23, val_loss: -2.322233860057509e+22, val_recall@10: 0.07761, val_precision@10: 0.01179, val_ndcg@10: 0.03836
2024-12-11 00:57:41,235 [Iteration 1400/5000] train_loss: -5.844565781898459e+22, val_loss: -3.677501870742131e+22, val_recall@10: 0.07563, val_precision@10: 0.01146, val_ndcg@10: 0.03781
2024-12-11 00:57:59,850 [Iteration 1600/5000] train_loss: -2.775805790048799e+22, val_loss: -4.481719338940879e+22, val_recall@10: 0.07594, val_precision@10: 0.01128, val_ndcg@10: 0.03756
2024-12-11 00:58:18,717 [Iteration 1800/5000] train_loss: -3.5787962525290703e+22, val_loss: -5.137786618977629e+22, val_recall@10: 0.07654, val_precision@10: 0.01132, val_ndcg@10: 0.03737
2024-12-11 00:58:37,314 [Iteration 2000/5000] train_loss: -6.912481393178725e+22, val_loss: -4.778204813209561e+22, val_recall@10: 0.07636, val_precision@10: 0.01136, val_ndcg@10: 0.03695
2024-12-11 00:58:55,633 [Iteration 2200/5000] train_loss: -5.247986549339646e+22, val_loss: -5.631179827234092e+22, val_recall@10: 0.07664, val_precision@10: 0.01139, val_ndcg@10: 0.03674
2024-12-11 00:59:14,319 [Iteration 2400/5000] train_loss: -1.3515023258561962e+23, val_loss: -7.0373256784490625e+22, val_recall@10: 0.07727, val_precision@10: 0.0115, val_ndcg@10: 0.03668
2024-12-11 00:59:32,887 [Iteration 2600/5000] train_loss: -4.0570091775215555e+22, val_loss: -6.024675539636111e+22, val_recall@10: 0.0758, val_precision@10: 0.01136, val_ndcg@10: 0.03604
2024-12-11 00:59:51,559 [Iteration 2800/5000] train_loss: -1.8111308767703593e+23, val_loss: -7.708689884980139e+22, val_recall@10: 0.07322, val_precision@10: 0.01114, val_ndcg@10: 0.03522
2024-12-11 01:00:10,029 [Iteration 3000/5000] train_loss: -4.573472975589149e+22, val_loss: -7.918583748493443e+22, val_recall@10: 0.07332, val_precision@10: 0.01114, val_ndcg@10: 0.03518
2024-12-11 01:00:28,441 [Iteration 3200/5000] train_loss: -3.997278386023703e+22, val_loss: -7.999584590671403e+22, val_recall@10: 0.07195, val_precision@10: 0.01103, val_ndcg@10: 0.03468
2024-12-11 01:00:46,236 [Iteration 3400/5000] train_loss: -9.647557078557548e+22, val_loss: -6.989227234428746e+22, val_recall@10: 0.0691, val_precision@10: 0.01099, val_ndcg@10: 0.03406
2024-12-11 01:01:04,774 [Iteration 3600/5000] train_loss: -5.662785639059015e+22, val_loss: -8.602956152188216e+22, val_recall@10: 0.06852, val_precision@10: 0.01074, val_ndcg@10: 0.03368
2024-12-11 01:01:23,228 [Iteration 3800/5000] train_loss: -4.751159346367313e+22, val_loss: -7.720076786277983e+22, val_recall@10: 0.06707, val_precision@10: 0.01056, val_ndcg@10: 0.03301
2024-12-11 01:01:42,424 [Iteration 4000/5000] train_loss: -6.521328453302864e+22, val_loss: -9.817545446492647e+22, val_recall@10: 0.06485, val_precision@10: 0.01045, val_ndcg@10: 0.03262
2024-12-11 01:02:01,110 [Iteration 4200/5000] train_loss: -6.952048218064951e+22, val_loss: -9.993623581843877e+22, val_recall@10: 0.06467, val_precision@10: 0.01031, val_ndcg@10: 0.03242
2024-12-11 01:02:19,463 [Iteration 4400/5000] train_loss: -9.206463722413776e+22, val_loss: -9.784109822139123e+22, val_recall@10: 0.06501, val_precision@10: 0.01024, val_ndcg@10: 0.03231
2024-12-11 01:02:38,161 [Iteration 4600/5000] train_loss: -5.3874760902382295e+22, val_loss: -1.0598470522598617e+23, val_recall@10: 0.06442, val_precision@10: 0.01013, val_ndcg@10: 0.03204
2024-12-11 01:02:56,814 [Iteration 4800/5000] train_loss: -1.1361984682545172e+23, val_loss: -1.073022332969734e+23, val_recall@10: 0.0646, val_precision@10: 0.01016, val_ndcg@10: 0.03239
2024-12-11 01:03:15,435 [Iteration 4999/5000] train_loss: -5.8177554029567596e+22, val_loss: -9.091894850053247e+22, val_recall@10: 0.0637, val_precision@10: 0.00995, val_ndcg@10: 0.03203
2024-12-11 01:03:15,584 Experiment K_50: best train loss -1.8111308767703593e+23; best val loss -1.8111308767703593e+23; last train loss -5.8177554029567596e+22; last val loss -5.8177554029567596e+22
2024-12-11 01:03:15,584 Experiment setup: {'batch_size': 1024, 'LR': 0.001, 'K': 100, 'name': 'K_100'}
2024-12-11 01:03:49,153 [Iteration 0/5000] train_loss: -1.08142, val_loss: -0.56284, val_recall@10: 0.01036, val_precision@10: 0.0009, val_ndcg@10: 0.00399
2024-12-11 01:04:22,478 [Iteration 200/5000] train_loss: -60985262080.0, val_loss: -47367217152.0, val_recall@10: 0.01979, val_precision@10: 0.00172, val_ndcg@10: 0.00871
2024-12-11 01:04:55,985 [Iteration 400/5000] train_loss: -2.060612350980915e+16, val_loss: -2.090006033412915e+16, val_recall@10: 0.06203, val_precision@10: 0.00483, val_ndcg@10: 0.02617
2024-12-11 01:05:29,192 [Iteration 600/5000] train_loss: -1.445788477312425e+20, val_loss: -1.2696117940534116e+20, val_recall@10: 0.11343, val_precision@10: 0.00841, val_ndcg@10: 0.04384
2024-12-11 01:06:02,328 [Iteration 800/5000] train_loss: -1.109847839280778e+22, val_loss: -7.86819387298272e+21, val_recall@10: 0.12982, val_precision@10: 0.00962, val_ndcg@10: 0.04957
2024-12-11 01:06:35,427 [Iteration 1000/5000] train_loss: -8.428414645029845e+22, val_loss: -1.3113733391464834e+22, val_recall@10: 0.12535, val_precision@10: 0.00939, val_ndcg@10: 0.04906
2024-12-11 01:07:08,403 [Iteration 1200/5000] train_loss: -1.999732441821396e+22, val_loss: -2.343183254444148e+22, val_recall@10: 0.1283, val_precision@10: 0.0094, val_ndcg@10: 0.04955
2024-12-11 01:07:41,441 [Iteration 1400/5000] train_loss: -1.9874682393161405e+22, val_loss: -2.1650607100420736e+22, val_recall@10: 0.12939, val_precision@10: 0.0094, val_ndcg@10: 0.05007
2024-12-11 01:08:14,608 [Iteration 1600/5000] train_loss: -3.86622003398752e+22, val_loss: -3.7058601368757574e+22, val_recall@10: 0.1323, val_precision@10: 0.00949, val_ndcg@10: 0.0507
2024-12-11 01:08:47,855 [Iteration 1800/5000] train_loss: -2.53379405543294e+22, val_loss: -4.373501442774868e+22, val_recall@10: 0.13364, val_precision@10: 0.00949, val_ndcg@10: 0.05083
2024-12-11 01:09:20,836 [Iteration 2000/5000] train_loss: -9.928259237572147e+22, val_loss: -5.402832013887675e+22, val_recall@10: 0.1364, val_precision@10: 0.00955, val_ndcg@10: 0.05133
2024-12-11 01:09:53,728 [Iteration 2200/5000] train_loss: -3.936192011038013e+22, val_loss: -5.694068993150619e+22, val_recall@10: 0.13574, val_precision@10: 0.00946, val_ndcg@10: 0.05094
2024-12-11 01:10:26,619 [Iteration 2400/5000] train_loss: -1.1022231325216491e+23, val_loss: -6.694485103575819e+22, val_recall@10: 0.13505, val_precision@10: 0.00948, val_ndcg@10: 0.05051
2024-12-11 01:10:59,824 [Iteration 2600/5000] train_loss: -5.130025115379819e+22, val_loss: -7.056102086015496e+22, val_recall@10: 0.13393, val_precision@10: 0.00939, val_ndcg@10: 0.05021
2024-12-11 01:11:32,887 [Iteration 2800/5000] train_loss: -2.137761240180842e+22, val_loss: -7.680197411577617e+22, val_recall@10: 0.13098, val_precision@10: 0.00922, val_ndcg@10: 0.04937
2024-12-11 01:12:05,950 [Iteration 3000/5000] train_loss: -3.6275454666955423e+22, val_loss: -8.468620080343233e+22, val_recall@10: 0.13146, val_precision@10: 0.00924, val_ndcg@10: 0.04943
2024-12-11 01:12:39,039 [Iteration 3200/5000] train_loss: -3.064225092204879e+22, val_loss: -9.123646128146134e+22, val_recall@10: 0.1287, val_precision@10: 0.0092, val_ndcg@10: 0.04878
2024-12-11 01:13:12,306 [Iteration 3400/5000] train_loss: -4.889617112591266e+22, val_loss: -9.289175932450137e+22, val_recall@10: 0.12856, val_precision@10: 0.00906, val_ndcg@10: 0.04845
2024-12-11 01:13:45,508 [Iteration 3600/5000] train_loss: -7.033697578589253e+22, val_loss: -1.0235370504801647e+23, val_recall@10: 0.12712, val_precision@10: 0.00901, val_ndcg@10: 0.04811
2024-12-11 01:14:18,709 [Iteration 3800/5000] train_loss: -8.214933214053378e+22, val_loss: -1.0924173549809828e+23, val_recall@10: 0.12594, val_precision@10: 0.0089, val_ndcg@10: 0.04762
2024-12-11 01:14:51,992 [Iteration 4000/5000] train_loss: -5.6628829168109665e+22, val_loss: -1.0922899031115282e+23, val_recall@10: 0.12337, val_precision@10: 0.00886, val_ndcg@10: 0.04713
2024-12-11 01:15:25,054 [Iteration 4200/5000] train_loss: -6.828931513611673e+22, val_loss: -1.1001314807107131e+23, val_recall@10: 0.12344, val_precision@10: 0.00881, val_ndcg@10: 0.047
2024-12-11 01:15:58,284 [Iteration 4400/5000] train_loss: -5.8797627640662475e+22, val_loss: -1.1247264489237163e+23, val_recall@10: 0.12273, val_precision@10: 0.00875, val_ndcg@10: 0.04662
2024-12-11 01:16:31,446 [Iteration 4600/5000] train_loss: -4.141055353767544e+22, val_loss: -1.2435380724211985e+23, val_recall@10: 0.12191, val_precision@10: 0.0087, val_ndcg@10: 0.04635
2024-12-11 01:17:04,560 [Iteration 4800/5000] train_loss: -1.9756743927559678e+23, val_loss: -1.2678291377313468e+23, val_recall@10: 0.12361, val_precision@10: 0.00872, val_ndcg@10: 0.04654
2024-12-11 01:17:37,466 [Iteration 4999/5000] train_loss: -3.023064218230545e+22, val_loss: -1.3880774095099602e+23, val_recall@10: 0.12349, val_precision@10: 0.00866, val_ndcg@10: 0.04648
2024-12-11 01:17:37,601 Experiment K_100: best train loss -1.9756743927559678e+23; best val loss -1.9756743927559678e+23; last train loss -3.023064218230545e+22; last val loss -3.023064218230545e+22
