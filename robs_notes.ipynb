{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d216dc5d98391e6f",
   "metadata": {},
   "source": [
    "# Graph Neural Networks\n",
    "## What are Graph Neural Networks (GNNs)?"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-12-06T18:22:56.341587Z",
     "start_time": "2024-12-06T18:22:48.532331Z"
    }
   },
   "source": [
    "#import the basics\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_sparse import SparseTensor\n",
    "%matplotlib inline"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:22:58.156247Z",
     "start_time": "2024-12-06T18:22:58.146067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch_geometric.seed_everything(1234)\n",
    "torch_geometric.__version__"
   ],
   "id": "e35d8b8b9e6c3dcc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "67fbe8da1fe75fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:23:00.545333Z",
     "start_time": "2024-12-06T18:23:00.541490Z"
    }
   },
   "source": [
    "# Let's verify what device we are working with\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You are using device: %s\" % device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Graph Neural Networks are a type of \"geometric deep learning\" models that use pairwise message passing. They typically have an architecture consisting of 3 types of layers. From [wikipedia](https://en.wikipedia.org/wiki/Graph_neural_network):\n",
    "1. Permutation equivariant: a permutation equivariant layer maps a representation of a graph into an updated representation of the same graph. In the literature, permutation equivariant layers are implemented via **pairwise message passing between graph nodes**. Intuitively, in a message passing layer, nodes update their representations by aggregating the messages received from their immediate neighbours. As such, each message passing layer increases the receptive field of the GNN by one hop.\n",
    "2. Local pooling: a local pooling layer coarsens the graph via downsampling. Local pooling is used to increase the receptive field of a GNN, in a similar fashion to pooling layers in convolutional neural networks. Examples include k-nearest neighbours pooling, top-k pooling, and self-attention pooling.\n",
    "3. Global pooling: a global pooling layer, also known as readout layer, provides fixed-size representation of the whole graph. The global pooling layer must be permutation invariant, such that permutations in the ordering of graph nodes and edges do not alter the final output. Examples include element-wise sum, mean or maximum.\n",
    "\n",
    "## Attributes\n",
    "- [T]he preprocessing step first\n",
    "“squashes” the graph structured data into a vector of reals and\n",
    "then deals with the preprocessed data using a list-based data\n",
    "processing technique. However, important information, e.g., the\n",
    "topological dependency of information on each node may be\n",
    "lost during the preprocessing stage and the final result may depend, in an unpredictable manner, on the details of the preprocessing algorith [1] **GNNS preserve the structure of the graph it is based on.**\n",
    "- It will be shown that the GNN\n",
    "is an extension of both recursive neural networks and random\n",
    "walk models and that it retains their characteristics. The model\n",
    "extends recursive neural networks since it can process a more\n",
    "general class of graphs including cyclic, directed, and undirected graphs, and it can deal with node-focused applications\n",
    "without any preprocessing steps. The approach extends random\n",
    "walk theory by the introduction of a learning algorithm and by\n",
    "enlarging the class of processes that can be modeled. [1]\n",
    "- Weights are shared across layer structures"
   ],
   "id": "2b01e644be17227d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What is message passing?\n",
    "From [wikipedia](https://en.wikipedia.org/wiki/Graph_neural_network#Message_passing_layers):\n",
    "<br>\n",
    "![img](./img/notebook/messagePassing.png)"
   ],
   "id": "5cf99a039651b47d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Computation Graph\n",
    "\"The neighbour of a node defines its computation graph\" - @12:34 https://www.youtube.com/watch?v=JtDgmmQ60x8&ab_channel=AntonioLonga\n",
    "\n"
   ],
   "id": "2a5502a902d3a34d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data",
   "id": "7a1ed8eba215733d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:23:06.159501Z",
     "start_time": "2024-12-06T18:23:06.151296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movie_path = './data/MovieLens/raw/ml-latest-small/movies.csv'\n",
    "rating_path = './data/MovieLens/raw/ml-latest-small/ratings.csv'"
   ],
   "id": "51603dbdf7f7f8d1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:23:11.877318Z",
     "start_time": "2024-12-06T18:23:11.787657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_node_csv(path, index_col):\n",
    "    \"\"\"Loads csv containing node information\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        index_col (str): column name of index column\n",
    "    Returns:\n",
    "        dict: mapping of csv row to node id\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, index_col=index_col)\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    return mapping\n",
    "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
    "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
   ],
   "id": "4e3b5b8ee1a2b987",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:23:16.532761Z",
     "start_time": "2024-12-06T18:23:16.526178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"user_mapping size: {len(user_mapping)}\")\n",
    "print(f\"movie_mapping size: {len(movie_mapping)}\")"
   ],
   "id": "388c5337a6a46337",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_mapping size: 610\n",
      "movie_mapping size: 9742\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:23:21.773800Z",
     "start_time": "2024-12-06T18:23:21.342755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        src_index_col (str): column name of users\n",
    "        src_mapping (dict): mapping between row number and user id\n",
    "        dst_index_col (str): column name of items\n",
    "        dst_mapping (dict): mapping between row number and item id\n",
    "        link_index_col (str): column name of user item interaction\n",
    "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    edge_index = None\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
    "\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "\n",
    "    return torch.tensor(edge_index)\n",
    "\n",
    "\n",
    "edge_index = load_edge_csv(\n",
    "    rating_path,\n",
    "    src_index_col='userId',\n",
    "    src_mapping=user_mapping,\n",
    "    dst_index_col='movieId',\n",
    "    dst_mapping=movie_mapping,\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=4,\n",
    ")"
   ],
   "id": "fb049113dd918ef4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:23:25.254271Z",
     "start_time": "2024-12-06T18:23:25.240909Z"
    }
   },
   "cell_type": "code",
   "source": "edge_index[:,:5]",
   "id": "c3d671383c9f0131",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0],\n",
       "        [ 0,  2,  5, 43, 46]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:23:42.886489Z",
     "start_time": "2024-12-06T18:23:42.878053Z"
    }
   },
   "cell_type": "code",
   "source": "edge_index.size()",
   "id": "20b5cca3ef650c18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 48580])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:00.369404Z",
     "start_time": "2024-12-06T18:23:59.609061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TOTAL_NUM_USERS, TOTAL_NUM_MOVIES = len(user_mapping), len(movie_mapping)\n",
    "num_interactions = edge_index.shape[1]\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=1)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    test_indices, test_size=0.5, random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ],
   "id": "46b7d1db54aec77d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:04.962993Z",
     "start_time": "2024-12-06T18:24:04.958118Z"
    }
   },
   "cell_type": "code",
   "source": "train_edge_index.size()[1]/edge_index.size()[1]",
   "id": "b7a0ff37526525af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:06.526452Z",
     "start_time": "2024-12-06T18:24:06.521462Z"
    }
   },
   "cell_type": "code",
   "source": "val_edge_index.size()[1]/edge_index.size()[1]",
   "id": "aeb61cc0081b4ac6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:07.602507Z",
     "start_time": "2024-12-06T18:24:07.597537Z"
    }
   },
   "cell_type": "code",
   "source": "test_edge_index.size()[1]/edge_index.size()[1]",
   "id": "2b7064e70f1687e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:23.354728Z",
     "start_time": "2024-12-06T18:24:23.314116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
    "    TOTAL_NUM_USERS + TOTAL_NUM_MOVIES, TOTAL_NUM_USERS + TOTAL_NUM_MOVIES))\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
    "    TOTAL_NUM_USERS + TOTAL_NUM_MOVIES, TOTAL_NUM_USERS + TOTAL_NUM_MOVIES))\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
    "    TOTAL_NUM_USERS + TOTAL_NUM_MOVIES, TOTAL_NUM_USERS + TOTAL_NUM_MOVIES))"
   ],
   "id": "bd22f39a2ea54a8f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:25.994140Z",
     "start_time": "2024-12-06T18:24:25.986936Z"
    }
   },
   "cell_type": "code",
   "source": "torch.stack([train_sparse_edge_index.coo()[0], train_sparse_edge_index.coo()[1]], dim=0)",
   "id": "b94fc3c83f7c6e7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
       "        [   0,    2,   43,  ..., 9461, 9462, 9463]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:32.570258Z",
     "start_time": "2024-12-06T18:24:32.564001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "train_data = HeteroData()\n",
    "train_data['user'].num_nodes = TOTAL_NUM_USERS\n",
    "train_data['movie'].num_nodes = TOTAL_NUM_MOVIES\n",
    "train_data['user','rates','movie'].edge_index = torch.stack([train_sparse_edge_index.coo()[0], train_sparse_edge_index.coo()[1]], dim=0)"
   ],
   "id": "c6b2bedc9660d280",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:34.414279Z",
     "start_time": "2024-12-06T18:24:34.402425Z"
    }
   },
   "cell_type": "code",
   "source": "train_data",
   "id": "c5db3361b14a76c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=610 },\n",
       "  movie={ num_nodes=9742 },\n",
       "  (user, rates, movie)={ edge_index=[2, 38864] }\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:37.900254Z",
     "start_time": "2024-12-06T18:24:37.890209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    train_data,\n",
    "    batch_size=1000,\n",
    "    num_neighbors=[30,20,10],\n",
    "    edge_label_index=('user','rates','movie'),\n",
    "    is_sorted=True,\n",
    "    shuffle=True,\n",
    ")"
   ],
   "id": "ebe88667444bd9d9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:24:43.155390Z",
     "start_time": "2024-12-06T18:24:43.114446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampled_data = next(iter(train_loader))\n",
    "sampled_data"
   ],
   "id": "ffdd50001a2ba9bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    num_nodes=374,\n",
       "    n_id=[374],\n",
       "  },\n",
       "  movie={\n",
       "    num_nodes=707,\n",
       "    n_id=[707],\n",
       "  },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 57],\n",
       "    e_id=[57],\n",
       "    input_id=[1000],\n",
       "    edge_label_index=[2, 1000],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:26:07.947402Z",
     "start_time": "2024-12-06T18:26:07.933747Z"
    }
   },
   "cell_type": "code",
   "source": "sampled_data['user','rates','movie']['edge_index']",
   "id": "a97f8f320d16fd4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0, 270,  34, 198, 368, 202,   5,\n",
       "         305, 162, 318, 152, 305,  82, 301, 369,  42, 305, 194, 290, 370, 116,\n",
       "          48, 193,  61, 278, 155, 224, 257, 290, 181, 371, 372, 373, 373, 373,\n",
       "         373],\n",
       "        [  0,   2,  16,  17,  24,  27,  32,  45,  63,  67,  70,  72,  75,  82,\n",
       "          90, 100, 101, 102, 105, 107, 111, 113, 117, 117, 117, 117, 117, 117,\n",
       "         117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,\n",
       "         117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 253, 615, 623, 633,\n",
       "         680]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:27:11.213927Z",
     "start_time": "2024-12-06T18:27:11.200821Z"
    }
   },
   "cell_type": "code",
   "source": "sampled_data['user','rates','movie']['e_id']",
   "id": "fb736a372cb3265",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,     3,     4,     5,     8,    10,    11,    12,\n",
       "           13,    14,    15,    17,    19,    21,    22,    23,    24,    25,\n",
       "           26,    27, 27041,  2576, 19317, 18873, 20033,   433, 31243, 15137,\n",
       "        32472, 13850, 31378,  7780, 30913,  7720,  3345, 31244, 19060, 28956,\n",
       "        22332, 10432,  3973, 18772,  5414, 27739, 14100, 21850, 24945, 29452,\n",
       "        17250,  9855, 32788, 32834, 32835, 32836, 32839])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.010541Z",
     "start_time": "2024-12-06T17:28:33.000165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_data = HeteroData()\n",
    "val_data['user'].num_nodes = TOTAL_NUM_USERS\n",
    "val_data['movie'].num_nodes = TOTAL_NUM_MOVIES\n",
    "val_data['user','rates','movie'].edge_index = torch.stack([val_sparse_edge_index.coo()[0], val_sparse_edge_index.coo()[1]], dim=0)\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    val_data,\n",
    "    batch_size=1000,\n",
    "    num_neighbors=[30,20,10],\n",
    "    edge_label_index=('user','rates','movie'),\n",
    "    is_sorted=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(train_loader))\n",
    "sampled_data"
   ],
   "id": "6b7a0b019d5bb82b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    num_nodes=363,\n",
       "    n_id=[363],\n",
       "  },\n",
       "  movie={\n",
       "    num_nodes=731,\n",
       "    n_id=[731],\n",
       "  },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 86],\n",
       "    e_id=[86],\n",
       "    input_id=[1000],\n",
       "    edge_label_index=[2, 1000],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Neural Graph Collaborative Filtering\n",
    "\n"
   ],
   "id": "ab517eeeb4c44c2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.037162Z",
     "start_time": "2024-12-06T17:28:33.025319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import Linear\n",
    "from torch.nn import Embedding, Parameter\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class EmbeddingPropLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=128):\n",
    "        super(EmbeddingPropLayer, self).__init__()\n",
    "\n",
    "        self.W1 = Linear(hidden_channels, hidden_channels, bias=False)\n",
    "        self.W2 = Linear(hidden_channels, hidden_channels, bias=False)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.W1.reset_parameters()\n",
    "        self.W2.reset_parameters()\n",
    "\n",
    "    def forward(self, E, E_final):\n",
    "        message = self.message_aggregation(E)\n",
    "        return message, torch.concat([E_final, message], dim=1)\n",
    "\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    def message_construction(self, E, p_ui):\n",
    "        return torch.mul(p_ui*E, p_ui*self.W2(E))\n",
    "\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    def message_aggregation(self, E):\n",
    "        p_ui = self._com\n",
    "        m_ui = self.message_construction(E, p_ui)\n",
    "        m_uu = p_ui*self.W1(E)\n",
    "        return F.leaky_relu(m_uu + m_ui)\n",
    "\n",
    "    def _compute_normalized_adjacency(self, ei):\n",
    "        \"\"\"Compute normalized adjacency matrix A' = D^(-1/2) * A * D^(-1/2)\"\"\"\n",
    "        edge_index_norm = gcn_norm(\n",
    "            ei,\n",
    "            add_self_loops=self.add_self_loops\n",
    "        )\n",
    "        return edge_index_norm\n",
    "\n",
    "class NGCF(torch.nn.Module):\n",
    "    def __init__(self, num_of_users, num_of_movies, hidden_channels=128):\n",
    "        super(NGCF, self).__init__()\n",
    "        self.num_of_users = num_of_users\n",
    "        self.num_of_movies = num_of_movies\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.user_emb_layer = Embedding(self.num_of_users, hidden_channels)\n",
    "        self.movie_emb_layer = Embedding(self.num_of_movies, hidden_channels)\n",
    "\n",
    "        self.embedding_prop_layer_1 = EmbeddingPropLayer(hidden_channels)\n",
    "        self.embedding_prop_layer_2 = EmbeddingPropLayer(hidden_channels)\n",
    "        self.embedding_prop_layer_3 = EmbeddingPropLayer(hidden_channels)\n",
    "\n",
    "    def forward(self, fdata, debug=False):\n",
    "        e_u_0 = self.user_emb_layer(fdata['user','rates','movie']['edge_label_index'][0])\n",
    "        e_i_0 = self.movie_emb_layer(fdata['user','rates','movie']['edge_label_index'][1])\n",
    "        E = torch.concat([e_u_0, e_i_0], dim=0)\n",
    "\n",
    "        if debug: print(f\"E size: {E.size()}\")\n",
    "\n",
    "        #assert E.size()[0] == self.num_of_edges and E.size()[1] == self.hidden_channels\n",
    "\n",
    "        E_1, E_star = self.embedding_prop_layer_1(E, torch.empty_like(E)) #E_l -> [num_users+num_movies,\n",
    "        E_2, E_star = self.embedding_prop_layer_2(E_1, E_star)\n",
    "        E_3, E_star = self.embedding_prop_layer_2(E_2, E_star)\n",
    "\n",
    "        #assert E_star.size()[0] == self.num_of_edges and E_star.size()[1] == self.hidden_channels*4\n",
    "\n",
    "        split_point = len(fdata['user','rates','movie']['edge_label_index'][0])\n",
    "\n",
    "        if debug:\n",
    "            print(f\"E_star size: {E_star.size()}\")\n",
    "            print(f\"split point: {split_point}\")\n",
    "\n",
    "        e_u_star = E_star[:split_point]\n",
    "        e_i_star = E_star[split_point:]\n",
    "\n",
    "        if debug:\n",
    "            print(f\"E size {E.size()}\")\n",
    "            print(f\"E star size {E_star.size()}\")\n",
    "            print(f\"e_u star size {e_u_star.size()}\")\n",
    "            print(f\"e_i star size {e_i_star.size()}\")\n",
    "            print(f\"e_u 0 size {e_u_0.size()}\")\n",
    "            print(f\"e_i 0 size {e_i_0.size()}\")\n",
    "\n",
    "        # users_emb_final, users_emb_0, items_emb_final, items_emb_0\n",
    "        return e_u_star, e_u_0, e_i_star, e_i_0\n"
   ],
   "id": "398d6f686d650d86",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.055711Z",
     "start_time": "2024-12-06T17:28:33.050551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2))\n",
    "\n",
    "    # print(f\"user emb final: {users_emb_final}\")\n",
    "    # print(f\"pos_items_emb_final: {pos_items_emb_final}\")\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1)\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1)\n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    "\n",
    "    # print(f\"pos scores: {pos_scores}\")\n",
    "    # print(f\"neg scores: {neg_scores}\")\n",
    "    # print(f\"pos - neg: {pos_scores - neg_scores}\")\n",
    "    # print(f\"reg_loss: {reg_loss}\")\n",
    "    # print(f\"Loss: {loss}\")\n",
    "\n",
    "    return loss"
   ],
   "id": "54600536a58699f3",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.072188Z",
     "start_time": "2024-12-06T17:28:33.068552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ],
   "id": "799d5e47dd0380bd",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.088095Z",
     "start_time": "2024-12-06T17:28:33.084408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (intg): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ],
   "id": "a00f65922cf3ce87",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.106795Z",
     "start_time": "2024-12-06T17:28:33.101570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ],
   "id": "2b0f13e646575ec3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.136356Z",
     "start_time": "2024-12-06T17:28:33.130224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.user_emb_layer.weight\n",
    "    item_embedding = model.movie_emb_layer.weight\n",
    "\n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ],
   "id": "f6b912d5c1b839c4",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.145708Z",
     "start_time": "2024-12-06T17:28:33.140627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(sparse_edge_index, debug=False)\n",
    "    edges = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
    "\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ],
   "id": "39a86c656cbb9f9f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.160924Z",
     "start_time": "2024-12-06T17:28:33.158399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ITERATIONS = 100\n",
    "BATCH_SIZE = 200\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ],
   "id": "247b78a2c08f9a3f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.208324Z",
     "start_time": "2024-12-06T17:28:33.174736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = NGCF(TOTAL_NUM_USERS, TOTAL_NUM_MOVIES, hidden_channels=128)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "print(model)"
   ],
   "id": "91e2bd7d8c3e77f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGCF(\n",
      "  (user_emb_layer): Embedding(610, 128)\n",
      "  (movie_emb_layer): Embedding(9742, 128)\n",
      "  (embedding_prop_layer_1): EmbeddingPropLayer(\n",
      "    (W1): Linear(128, 128, bias=False)\n",
      "    (W2): Linear(128, 128, bias=False)\n",
      "  )\n",
      "  (embedding_prop_layer_2): EmbeddingPropLayer(\n",
      "    (W1): Linear(128, 128, bias=False)\n",
      "    (W2): Linear(128, 128, bias=False)\n",
      "  )\n",
      "  (embedding_prop_layer_3): EmbeddingPropLayer(\n",
      "    (W1): Linear(128, 128, bias=False)\n",
      "    (W2): Linear(128, 128, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.229303Z",
     "start_time": "2024-12-06T17:28:33.222214Z"
    }
   },
   "cell_type": "code",
   "source": "next(iter(train_loader))",
   "id": "5f4466fff489719",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    num_nodes=353,\n",
       "    n_id=[353],\n",
       "  },\n",
       "  movie={\n",
       "    num_nodes=725,\n",
       "    n_id=[725],\n",
       "  },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 85],\n",
       "    e_id=[85],\n",
       "    input_id=[1000],\n",
       "    edge_label_index=[2, 1000],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:33.306187Z",
     "start_time": "2024-12-06T17:28:33.298939Z"
    }
   },
   "cell_type": "code",
   "source": "print(next(iter(train_loader))['user','rates','movie']['edge_label_index'])",
   "id": "c43bf1906190a9c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 54, 248,  98,  ..., 257,  36, 248],\n",
      "        [629, 159, 483,  ..., 429,  48, 501]])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:28:42.409801Z",
     "start_time": "2024-12-06T17:28:39.424519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for step in tqdm(range(ITERATIONS)):\n",
    "    train_data = next(iter(train_loader))\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "       train_data, debug=False)\n",
    "\n",
    "    print(f\"user emb final: {users_emb_final}\")\n",
    "\n",
    "    # print(f\"Sampling started ...\")\n",
    "    sampling = structured_negative_sampling(train_data['user','rates','movie']['edge_label_index'])\n",
    "    # print(f\"Sampling completed...\")\n",
    "\n",
    "    user_indices = sampling[0]\n",
    "    pos_item_indices = sampling[1]\n",
    "    neg_item_indices = sampling[2]\n",
    "\n",
    "    # print(f\"user_indices size: {user_indices.size()}\")\n",
    "    # print(f\"items_emb_final size: {items_emb_final.size()}\")\n",
    "    # print(f\"pos_item_indices size: {pos_item_indices.size()}\")\n",
    "    # print(f\"neg_item_indices size: {neg_item_indices.size()}\")\n",
    "\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_data = next(iter(val_loader))\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            # model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val\n",
    "            model, val_data['user','rates','movie']['edge_label_index'], val_data, [train_edge_index], K, LAMBDA)\n",
    "        print(f\"[Iteration {step}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    # if step % ITERS_PER_LR_DECAY == 0 and step != 0:\n",
    "    #    scheduler.step()"
   ],
   "id": "ad08b6c3df59cb07",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user emb final: tensor([[ 1.1710e-19,  1.3563e-19,  4.6135e+24,  ..., -5.5334e-04,\n",
      "         -1.7759e-03,  1.2467e-01],\n",
      "        [ 4.6135e+24,  4.1723e-08,  1.7117e-10,  ...,  3.0934e-02,\n",
      "         -3.1482e-04,  6.3413e-02],\n",
      "        [ 1.7118e-10,  9.1678e-33,  1.3563e-19,  ..., -2.7094e-03,\n",
      "          2.5165e-01, -4.8617e-04],\n",
      "        ...,\n",
      "        [ 1.7117e-10,  9.1671e-33,  1.3563e-19,  ..., -8.5050e-05,\n",
      "         -6.3595e-03,  1.1774e-01],\n",
      "        [ 1.1060e-02,  2.2310e-01,  1.3563e-19,  ...,  8.0087e-02,\n",
      "         -1.1108e-04,  9.6172e-02],\n",
      "        [ 1.0741e-05,  1.8018e+22,  1.3556e-19,  ...,  1.3924e-02,\n",
      "         -1.7881e-03,  1.1394e-01]], grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/torch/autograd/__init__.py:266: UserWarning: Error detected in SoftplusBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/robmayo/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/g0/5y8wr1dx15s181wqqnbkjn8r0000gn/T/ipykernel_42845/488436939.py\", line 33, in <module>\n",
      "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
      "  File \"/var/folders/g0/5y8wr1dx15s181wqqnbkjn8r0000gn/T/ipykernel_42845/2124497318.py\", line 26, in bpr_loss\n",
      "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
      " (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:118.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'SoftplusBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 37\u001B[0m\n\u001B[1;32m     33\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n\u001B[1;32m     34\u001B[0m                       pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n\u001B[1;32m     36\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 37\u001B[0m \u001B[43mtrain_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m%\u001B[39m ITERS_PER_EVAL \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/gnn-ass-env-cpu/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Function 'SoftplusBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a074183057c1692"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
