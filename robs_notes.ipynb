{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d216dc5d98391e6f",
   "metadata": {},
   "source": [
    "# Graph Neural Networks\n",
    "## What are Graph Neural Networks (GNNs)?"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:05.887832Z",
     "start_time": "2024-12-01T22:29:01.861834Z"
    }
   },
   "source": [
    "#import the basics\n",
    "import random\n",
    "from sched import scheduler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn as nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.datasets import AmazonBook, MovieLens\n",
    "from torch_geometric.transforms import Compose, ToDevice, ToUndirected\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:05.918840Z",
     "start_time": "2024-12-01T22:29:05.893834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch_geometric.seed_everything(1234)\n",
    "torch_geometric.__version__"
   ],
   "id": "e35d8b8b9e6c3dcc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "67fbe8da1fe75fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:05.982839Z",
     "start_time": "2024-12-01T22:29:05.967832Z"
    }
   },
   "source": [
    "# Let's verify what device we are working with\n",
    "device = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You are using device: %s\" % device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Graph Neural Networks are a type of \"geometric deep learning\" models that use pairwise message passing. They typically have an architecture consisting of 3 types of layers. From [wikipedia](https://en.wikipedia.org/wiki/Graph_neural_network):\n",
    "1. Permutation equivariant: a permutation equivariant layer maps a representation of a graph into an updated representation of the same graph. In the literature, permutation equivariant layers are implemented via **pairwise message passing between graph nodes**. Intuitively, in a message passing layer, nodes update their representations by aggregating the messages received from their immediate neighbours. As such, each message passing layer increases the receptive field of the GNN by one hop.\n",
    "2. Local pooling: a local pooling layer coarsens the graph via downsampling. Local pooling is used to increase the receptive field of a GNN, in a similar fashion to pooling layers in convolutional neural networks. Examples include k-nearest neighbours pooling, top-k pooling, and self-attention pooling.\n",
    "3. Global pooling: a global pooling layer, also known as readout layer, provides fixed-size representation of the whole graph. The global pooling layer must be permutation invariant, such that permutations in the ordering of graph nodes and edges do not alter the final output. Examples include element-wise sum, mean or maximum.\n",
    "\n",
    "## Attributes\n",
    "- [T]he preprocessing step first\n",
    "“squashes” the graph structured data into a vector of reals and\n",
    "then deals with the preprocessed data using a list-based data\n",
    "processing technique. However, important information, e.g., the\n",
    "topological dependency of information on each node may be\n",
    "lost during the preprocessing stage and the final result may depend, in an unpredictable manner, on the details of the preprocessing algorith [1] **GNNS preserve the structure of the graph it is based on.**\n",
    "- It will be shown that the GNN\n",
    "is an extension of both recursive neural networks and random\n",
    "walk models and that it retains their characteristics. The model\n",
    "extends recursive neural networks since it can process a more\n",
    "general class of graphs including cyclic, directed, and undirected graphs, and it can deal with node-focused applications\n",
    "without any preprocessing steps. The approach extends random\n",
    "walk theory by the introduction of a learning algorithm and by\n",
    "enlarging the class of processes that can be modeled. [1]\n",
    "- Weights are shared across layer structures"
   ],
   "id": "2b01e644be17227d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What is message passing?\n",
    "From [wikipedia](https://en.wikipedia.org/wiki/Graph_neural_network#Message_passing_layers):\n",
    "<br>\n",
    "![img](./img/notebook/messagePassing.png)"
   ],
   "id": "5cf99a039651b47d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Computation Graph\n",
    "\"The neighbour of a node defines its computation graph\" - @12:34 https://www.youtube.com/watch?v=JtDgmmQ60x8&ab_channel=AntonioLonga\n",
    "\n"
   ],
   "id": "2a5502a902d3a34d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.014832Z",
     "start_time": "2024-12-01T22:29:05.999832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saved_tensors = torch.load('sparse_tensors.pt')\n",
    "train_sparse = saved_tensors['train_sparse']\n",
    "val_sparse = saved_tensors['val_sparse']\n",
    "test_sparse = saved_tensors['test_sparse']\n",
    "\n",
    "sparse_sizes = train_sparse.sparse_sizes()\n",
    "num_users = num_items = sparse_sizes[0] // 2\n",
    "print(f\"Number of users/items: {num_users}\")\n",
    "print(f\"Size of sparse matrix: {sparse_sizes}\")\n",
    "\n",
    "train_edge_index = torch.stack([train_sparse.storage.row(), train_sparse.storage.col()])\n",
    "val_edge_index = torch.stack([val_sparse.storage.row(), val_sparse.storage.col()])\n",
    "\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "train_sparse = train_sparse.to(device)\n",
    "val_sparse = val_sparse.to(device)"
   ],
   "id": "11eec890cfb6607a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users/items: 5167\n",
      "Size of sparse matrix: (10334, 10334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob\\AppData\\Local\\Temp\\ipykernel_12748\\3870268926.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_tensors = torch.load('sparse_tensors.pt')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.046832Z",
     "start_time": "2024-12-01T22:29:06.032833Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_sparse.storage.row()[100:200])",
   "id": "1ce98828dd696c06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.078832Z",
     "start_time": "2024-12-01T22:29:06.064833Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_sparse.storage.col()[100:200])",
   "id": "abade3e922e645e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([752, 754, 755, 757, 760, 761, 767, 769, 770, 771, 772, 774, 775, 777,\n",
      "        778, 781, 783, 785, 786, 788, 789, 790, 791, 792, 793, 796, 797, 798,\n",
      "        800, 801, 803, 804, 805, 809, 810, 811, 813, 814, 818, 820, 821, 823,\n",
      "        824, 825, 826, 827, 828, 829, 831, 833, 834, 835, 836, 837, 838, 840,\n",
      "        841, 843, 844, 846, 847, 849, 850, 852, 855, 856, 857, 858, 862, 864,\n",
      "        868, 712, 834, 873, 882, 884, 885, 888, 893, 896, 897, 898, 899, 635,\n",
      "        644, 654, 662, 670, 671, 678, 679, 684, 686, 698, 707, 708, 718, 726,\n",
      "        737, 751])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Neural Graph Collaborative Filtering\n",
    "\n"
   ],
   "id": "ab517eeeb4c44c2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:52:01.572800Z",
     "start_time": "2024-12-01T22:52:01.549802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import Linear\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class EmbeddingPropLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=128):\n",
    "        super(EmbeddingPropLayer, self).__init__()\n",
    "\n",
    "        self.W1 = Linear(hidden_channels, hidden_channels, bias=False)\n",
    "        self.W2 = Linear(hidden_channels, hidden_channels, bias=False)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.W1.reset_parameters()\n",
    "        self.W2.reset_parameters()\n",
    "\n",
    "    def forward(self, E, E_final):\n",
    "        message = self.message_aggregation(E)\n",
    "        return message, torch.concat([E_final, message], dim=1)\n",
    "\n",
    "    def message_construction(self, E, p_ui):\n",
    "        return torch.mul(p_ui*E, p_ui*self.W2(E))\n",
    "\n",
    "    def message_aggregation(self, E):\n",
    "        p_ui = 1\n",
    "        m_ui = self.message_construction(E, p_ui)\n",
    "        m_uu = p_ui*self.W1(E)\n",
    "        return F.leaky_relu(m_uu + m_ui)\n",
    "\n",
    "\n",
    "class EmbeddingLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        user u and item i with an embedding vector e_u that's an element of d real numbers\n",
    "        and e_i that's an element of a d real numbers\n",
    "    \"\"\"\n",
    "    def __init__(self, num_of_edges, hidden_channels=128):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.user_embedding = Embedding(num_of_edges, hidden_channels)\n",
    "        self.movie_embedding = Embedding(num_of_edges, hidden_channels)\n",
    "\n",
    "    def forward(self, user_nodes, movie_nodes):\n",
    "        e_u = self.user_embedding(user_nodes)\n",
    "        e_i = self.movie_embedding(movie_nodes)\n",
    "        E = torch.concat([e_u, e_i])\n",
    "\n",
    "        return E\n",
    "\n",
    "class NGCF(torch.nn.Module):\n",
    "    def __init__(self, num_of_users, num_of_movies, hidden_channels=128):\n",
    "        super(NGCF, self).__init__()\n",
    "        self.num_of_users = num_of_users\n",
    "        self.num_of_movies = num_of_movies\n",
    "        self.num_of_edges = num_of_users + num_of_movies\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.embeddings = EmbeddingLayer(self.num_of_edges, hidden_channels)\n",
    "\n",
    "        self.embedding_prop_layer_1 = EmbeddingPropLayer(hidden_channels)\n",
    "        self.embedding_prop_layer_2 = EmbeddingPropLayer(hidden_channels)\n",
    "        self.embedding_prop_layer_3 = EmbeddingPropLayer(hidden_channels)\n",
    "\n",
    "\n",
    "    def forward(self, user_nodes, movie_nodes):\n",
    "        E = self.embeddings(user_nodes, movie_nodes) # size -> [num_users + num_movies, hidden_channels]\n",
    "\n",
    "        #assert E.size()[0] == self.num_of_edges and E.size()[1] == self.hidden_channels\n",
    "\n",
    "        E_1, E_star = self.embedding_prop_layer_1(E, torch.empty_like(E)) #E_l -> [num_users+num_movies,\n",
    "        E_2, E_star = self.embedding_prop_layer_2(E_1, E_star)\n",
    "        E_3, E_star = self.embedding_prop_layer_2(E_2, E_star)\n",
    "\n",
    "        #assert E_star.size()[0] == self.num_of_edges and E_star.size()[1] == self.hidden_channels*4\n",
    "\n",
    "        e_u_star = E_star[:(self.num_of_users-1), :]\n",
    "        e_i_star = E_star[self.num_of_users:, :]\n",
    "\n",
    "        # users_emb_final, users_emb_0, items_emb_final, items_emb_0\n",
    "        return e_u_star, E[:(self.num_of_users-1), :], e_i_star, E_star[self.num_of_users:, :]\n"
   ],
   "id": "398d6f686d650d86",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.142839Z",
     "start_time": "2024-12-01T22:29:06.127833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2))\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1)\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1)\n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    "\n",
    "    return loss"
   ],
   "id": "54600536a58699f3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.174839Z",
     "start_time": "2024-12-01T22:29:06.159832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_batch(batch_size, edge_index):\n",
    " # returns a tuple of 3 tensors. Tensor 1 -> user, Tensor 2 -> positive interactions, Tensor3-> Neg interactions\n",
    "   edges = structured_negative_sampling(edge_index)\n",
    "   edges = torch.stack(edges, dim=0)\n",
    "   indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "   batch = edges[:, indices]\n",
    "   user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "   return user_indices, pos_item_indices, neg_item_indices\n"
   ],
   "id": "75f02bd6302f4fda",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.206838Z",
     "start_time": "2024-12-01T22:29:06.191832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_ground_truth(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user efficiently.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {user.item(): [] for user in edge_index[0].unique()}\n",
    "    for user, item in zip(edge_index[0], edge_index[1]):\n",
    "        user_pos_items[user.item()].append(item.item())\n",
    "\n",
    "    return user_pos_items"
   ],
   "id": "98c6613213f4e360",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.237840Z",
     "start_time": "2024-12-01T22:29:06.222834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def metrics(groundTruth, r, k):\n",
    "    num_correct_pred = torch.sum(r, dim=-1).float()\n",
    "    user_num_liked = torch.tensor([len(groundTruth[i]) for i in range(len(groundTruth))], dtype=torch.float)\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ],
   "id": "2b0f13e646575ec3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.269838Z",
     "start_time": "2024-12-01T22:29:06.255834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        user_pos_items = get_ground_truth(exclude_edge_index)\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_ground_truth(edge_index)\n",
    "\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = metrics(test_user_pos_items_list, r, k)\n",
    "    # ndcg =\n",
    "\n",
    "    return recall, precision, 0"
   ],
   "id": "f6b912d5c1b839c4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:50:38.749235Z",
     "start_time": "2024-12-01T22:50:38.730227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        sparse_edge_index.storage.row(), sparse_edge_index.storage.col())\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ],
   "id": "39a86c656cbb9f9f",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:29:06.333840Z",
     "start_time": "2024-12-01T22:29:06.320833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ],
   "id": "247b78a2c08f9a3f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:59:36.143375Z",
     "start_time": "2024-12-01T22:59:35.993375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = NGCF(len(train_sparse.storage.row()), len(train_sparse.storage.col()), hidden_channels=128)\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "print(model)"
   ],
   "id": "91e2bd7d8c3e77f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGCF(\n",
      "  (embeddings): EmbeddingLayer(\n",
      "    (user_embedding): Embedding(155456, 128)\n",
      "    (movie_embedding): Embedding(155456, 128)\n",
      "  )\n",
      "  (embedding_prop_layer_1): EmbeddingPropLayer(\n",
      "    (W1): Linear(128, 128, bias=False)\n",
      "    (W2): Linear(128, 128, bias=False)\n",
      "  )\n",
      "  (embedding_prop_layer_2): EmbeddingPropLayer(\n",
      "    (W1): Linear(128, 128, bias=False)\n",
      "    (W2): Linear(128, 128, bias=False)\n",
      "  )\n",
      "  (embedding_prop_layer_3): EmbeddingPropLayer(\n",
      "    (W1): Linear(128, 128, bias=False)\n",
      "    (W2): Linear(128, 128, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T22:59:39.753374Z",
     "start_time": "2024-12-01T22:59:38.356375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for iter in tqdm(range(ITERATIONS)):\n",
    "   users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "       train_sparse.storage.row(), train_sparse.storage.col())\n",
    "\n",
    "   user_indices, pos_item_indices, neg_item_indices = sample_batch(\n",
    "       BATCH_SIZE, train_edge_index)\n",
    "   user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "       device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "   users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "   pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "       pos_item_indices], items_emb_0[pos_item_indices]\n",
    "   neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "       neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "   train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                         pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    "\n",
    "   optimizer.zero_grad()\n",
    "   train_loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "   if iter % ITERS_PER_EVAL == 0:\n",
    "       model.eval()\n",
    "       val_loss, recall, precision, ndcg = evaluation(\n",
    "           model, val_edge_index, val_sparse, [train_edge_index], K, LAMBDA)\n",
    "       print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "       train_losses.append(train_loss.item())\n",
    "       val_losses.append(val_loss)\n",
    "       model.train()\n",
    "\n",
    "   if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "       scheduler.step()"
   ],
   "id": "ad08b6c3df59cb07",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index is out of bounds for dimension with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;241m%\u001B[39m ITERS_PER_EVAL \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     28\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m---> 29\u001B[0m     val_loss, recall, precision, ndcg \u001B[38;5;241m=\u001B[39m \u001B[43mevaluation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_edge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_sparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_edge_index\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mK\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLAMBDA\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Iteration \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28miter\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mITERATIONS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] train_loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(train_loss\u001B[38;5;241m.\u001B[39mitem(),\u001B[38;5;250m \u001B[39m\u001B[38;5;241m5\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(val_loss,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m5\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_recall@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mK\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(recall,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m5\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_precision@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mK\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(precision,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m5\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_ndcg@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mK\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(ndcg,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m5\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     32\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "Cell \u001B[1;32mIn[38], line 21\u001B[0m, in \u001B[0;36mevaluation\u001B[1;34m(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val)\u001B[0m\n\u001B[0;32m     19\u001B[0m user_indices, pos_item_indices, neg_item_indices \u001B[38;5;241m=\u001B[39m edges[\u001B[38;5;241m0\u001B[39m], edges[\u001B[38;5;241m1\u001B[39m], edges[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m     20\u001B[0m users_emb_final, users_emb_0 \u001B[38;5;241m=\u001B[39m users_emb_final[user_indices], users_emb_0[user_indices]\n\u001B[1;32m---> 21\u001B[0m pos_items_emb_final, pos_items_emb_0 \u001B[38;5;241m=\u001B[39m \u001B[43mitems_emb_final\u001B[49m\u001B[43m[\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpos_item_indices\u001B[49m\u001B[43m]\u001B[49m, items_emb_0[pos_item_indices]\n\u001B[0;32m     23\u001B[0m neg_items_emb_final, neg_items_emb_0 \u001B[38;5;241m=\u001B[39m items_emb_final[\n\u001B[0;32m     24\u001B[0m     neg_item_indices], items_emb_0[neg_item_indices]\n\u001B[0;32m     26\u001B[0m loss \u001B[38;5;241m=\u001B[39m bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n\u001B[0;32m     27\u001B[0m                 neg_items_emb_final, neg_items_emb_0, lambda_val)\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[1;31mIndexError\u001B[0m: index is out of bounds for dimension with size 0"
     ]
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
