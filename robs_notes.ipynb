{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d216dc5d98391e6f",
   "metadata": {},
   "source": [
    "# Graph Neural Networks\n",
    "## What are Graph Neural Networks (GNNs)?"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-11-24T21:31:17.236941Z",
     "start_time": "2024-11-24T21:31:17.222943Z"
    }
   },
   "source": [
    "#import the basics\n",
    "import os\n",
    "import torch\n",
    "import torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:31:17.268941Z",
     "start_time": "2024-11-24T21:31:17.243943Z"
    }
   },
   "cell_type": "code",
   "source": "torch_geometric.__version__",
   "id": "e35d8b8b9e6c3dcc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "67fbe8da1fe75fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:31:17.300941Z",
     "start_time": "2024-11-24T21:31:17.285943Z"
    }
   },
   "source": [
    "# Let's verify what device we are working with\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"You are using device: %s\" % device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: cuda\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Graph Neural Networks are a type of \"geometric deep learning\" models that use pairwise message passing. They typically have an architecture consisting of 3 types of layers. From [wikipedia](https://en.wikipedia.org/wiki/Graph_neural_network):\n",
    "1. Permutation equivariant: a permutation equivariant layer maps a representation of a graph into an updated representation of the same graph. In the literature, permutation equivariant layers are implemented via **pairwise message passing between graph nodes**. Intuitively, in a message passing layer, nodes update their representations by aggregating the messages received from their immediate neighbours. As such, each message passing layer increases the receptive field of the GNN by one hop.\n",
    "2. Local pooling: a local pooling layer coarsens the graph via downsampling. Local pooling is used to increase the receptive field of a GNN, in a similar fashion to pooling layers in convolutional neural networks. Examples include k-nearest neighbours pooling, top-k pooling, and self-attention pooling.\n",
    "3. Global pooling: a global pooling layer, also known as readout layer, provides fixed-size representation of the whole graph. The global pooling layer must be permutation invariant, such that permutations in the ordering of graph nodes and edges do not alter the final output. Examples include element-wise sum, mean or maximum.\n",
    "\n",
    "## Attributes\n",
    "- [T]he preprocessing step first\n",
    "“squashes” the graph structured data into a vector of reals and\n",
    "then deals with the preprocessed data using a list-based data\n",
    "processing technique. However, important information, e.g., the\n",
    "topological dependency of information on each node may be\n",
    "lost during the preprocessing stage and the final result may depend, in an unpredictable manner, on the details of the preprocessing algorith [1] **GNNS preserve the structure of the graph it is based on.**\n",
    "- It will be shown that the GNN\n",
    "is an extension of both recursive neural networks and random\n",
    "walk models and that it retains their characteristics. The model\n",
    "extends recursive neural networks since it can process a more\n",
    "general class of graphs including cyclic, directed, and undirected graphs, and it can deal with node-focused applications\n",
    "without any preprocessing steps. The approach extends random\n",
    "walk theory by the introduction of a learning algorithm and by\n",
    "enlarging the class of processes that can be modeled. [1]\n",
    "- Weights are shared across layer structures"
   ],
   "id": "2b01e644be17227d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What is message passing?\n",
    "From [wikipedia](https://en.wikipedia.org/wiki/Graph_neural_network#Message_passing_layers):\n",
    "<br>\n",
    "![img](./img/notebook/messagePassing.png)"
   ],
   "id": "5cf99a039651b47d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Computation Graph\n",
    "\"The neighbour of a node defines its computation graph\" - @12:34 https://www.youtube.com/watch?v=JtDgmmQ60x8&ab_channel=AntonioLonga\n",
    "\n"
   ],
   "id": "2a5502a902d3a34d"
  },
  {
   "cell_type": "markdown",
   "id": "96e4180648083ec0",
   "metadata": {},
   "source": [
    "# Data\n",
    "Heterogeneous graphs are perfect for recommendation systems. Let's examine a data set from pytorch geometric to understand some basics about the data.\n",
    "\n",
    "### Datasets:\n",
    "\"AmazonBook\" - A subset of the AmazonBook rating dataset from the \"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation\" paper.\n",
    "\n",
    "\"MovieLens\" - A heterogeneous rating dataset, assembled by GroupLens Research from the MovieLens website, consisting of nodes of type \"movie\" and \"user\". User ratings for movies are available as ground truth labels for the edges between the users and the movies (\"user\", \"rates\", \"movie\")."
   ]
  },
  {
   "cell_type": "code",
   "id": "b687c078a44f1888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:28:19.267844Z",
     "start_time": "2024-11-25T22:28:19.218845Z"
    }
   },
   "source": [
    "from torch_geometric.datasets import AmazonBook, MovieLens\n",
    "from torch_geometric.transforms import Compose, ToDevice, ToUndirected\n",
    "\n",
    "transform = Compose([ToDevice(device), ToUndirected()])\n",
    "\n",
    "# amazon_dataset = AmazonBook(root=\"./data/AmazonBook\")\n",
    "movielens_dataset = MovieLens(root=\"./data/MovieLens\", transform=transform, model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "print(f\"Dataset: {movielens_dataset}\")\n",
    "print(f\"Number of graphs in dataset: {len(movielens_dataset)}\")\n",
    "print(f\"Number of features of dataset: {movielens_dataset.num_features}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: MovieLens()\n",
      "Number of graphs in dataset: 1\n",
      "Number of features of dataset: {'movie': 404, 'user': 0}\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:28:22.513076Z",
     "start_time": "2024-11-25T22:28:22.437076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = movielens_dataset[0]\n",
    "print(f\"data = Dataset[0]: {data}\")\n",
    "\n",
    "print(f\"Number of node features of data: {data.num_features}\")\n",
    "print(f\"Number of edge features of data: {data.num_edge_features}\")\n",
    "print(f\"Number of nodes of data: {data.num_nodes}\")\n",
    "print(f\"Number of edges of data: {data.num_edges}\")\n",
    "print(f\"data is directed?: {data.is_directed()}\")\n",
    "print(f\"data has isolated nodes?: {data.has_isolated_nodes()}\")\n",
    "print(f\"data contains self loops?: {data.has_self_loops()}\")\n",
    "print(f\"data node types: {data.node_types}\")\n",
    "print(f\"data edge types: {data.edge_types}\")\n",
    "print(f\"data is on device: {'CUDA' if data.is_cuda else 'CPU'}\")"
   ],
   "id": "cbbdf32a18a33fc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = Dataset[0]: HeteroData(\n",
      "  movie={ x=[9742, 404] },\n",
      "  user={ num_nodes=610 },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 100836],\n",
      "    edge_label=[100836],\n",
      "    time=[100836],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 100836],\n",
      "    edge_label=[100836],\n",
      "    time=[100836],\n",
      "  }\n",
      ")\n",
      "Number of node features of data: {'movie': 404, 'user': 0}\n",
      "Number of edge features of data: {('user', 'rates', 'movie'): 0, ('movie', 'rev_rates', 'user'): 0}\n",
      "Number of nodes of data: 10352\n",
      "Number of edges of data: 201672\n",
      "data is directed?: False\n",
      "data has isolated nodes?: True\n",
      "data contains self loops?: False\n",
      "data node types: ['movie', 'user']\n",
      "data edge types: [('user', 'rates', 'movie'), ('movie', 'rev_rates', 'user')]\n",
      "data is on device: CUDA\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:28:28.149545Z",
     "start_time": "2024-11-25T22:28:28.122537Z"
    }
   },
   "cell_type": "code",
   "source": "data.validate(raise_on_error=True)",
   "id": "2a69142adb053966",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:31:17.570942Z",
     "start_time": "2024-11-24T21:31:17.557942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(f\"Number of training edges: {data['user','rates','book'].edge_index.shape[1]}\")\n",
    "# print(f\"Number of testing edges: {data['user','rates','book'].edge_label_index.shape[1]}\")"
   ],
   "id": "8a6a2037a53aa1a9",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:31:17.602942Z",
     "start_time": "2024-11-24T21:31:17.588942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(f\"{torch.min(data['user', 'rates', 'book'].edge_index[0])}\")\n",
    "# print(f\"{torch.max(data['user', 'rates', 'book'].edge_index[0])}\")"
   ],
   "id": "11eec890cfb6607a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Because there are no features on the edges or the nodes, the connections (edges) themselves are what we are training on.",
   "id": "ea59f67045bbee28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Link Prediction on MovieLens.ipynb - https://colab.research.google.com/drive/1xpzn1Nvai1ygd_P5Yambc_oe4VBPK_ZT?usp=sharing#scrollTo=JMGYv83WzSRr\n",
    "- [1] Neural Graph Collaborative Filtering - https://dl.acm.org/doi/pdf/10.1145/3331184.3331267"
   ],
   "id": "d19971e5e6b2f42e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:28:32.573717Z",
     "start_time": "2024-11-25T22:28:32.566717Z"
    }
   },
   "cell_type": "code",
   "source": "torch_geometric.seed_everything(1234)",
   "id": "e5e29466b0ed72e7",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Naive Graph Neural Network\n",
    "\n"
   ],
   "id": "ab517eeeb4c44c2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:17:07.547075Z",
     "start_time": "2024-11-26T01:17:07.529068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import MLP, MessagePassing, Linear\n",
    "from torch.nn import Embedding\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\"\"\"\n",
    "    GNN layer consists of:\n",
    "        1.\n",
    "        2.\n",
    "        3.\n",
    "\"\"\"\n",
    "\n",
    "class GNNLayer(MessagePassing):\n",
    "    def __init__(self, hidden_channels=12800, aggr='add'):\n",
    "        super(GNNLayer, self).__init__(aggr=aggr)\n",
    "        self.message_function = MLP(in_channels= 2*404,\n",
    "                                    hidden_channels=hidden_channels,\n",
    "                                    out_channels=hidden_channels, num_layers=2) # default activation is ReLU\n",
    "        self.update_function = MLP(in_channels=hidden_channels,\n",
    "                                   hidden_channels=hidden_channels,\n",
    "                                   out_channels=2*404, num_layers=2) # default activation is ReLU\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.message_function.reset_parameters()\n",
    "        self.update_function.reset_parameters()\n",
    "\n",
    "    def forward(self, edge_index, x):\n",
    "        return self.propagate(edge_index=edge_index, x=x)\n",
    "\n",
    "    def message(self,x_j, x_i):\n",
    "        # (i,j)         -> source to target\n",
    "        # x_j           [N, num_of_features]\n",
    "        return self.message_function(torch.concat([x_i, x_j], dim=1))\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.update_function(aggr_out)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=1280, aggr='add'):\n",
    "        super(GNN, self).__init__()\n",
    "        self.gnn_layer_1 = GNNLayer(hidden_channels=hidden_channels, aggr=aggr)\n",
    "\n",
    "    def forward(self, edge_index, x):\n",
    "        out = self.gnn_layer_1(edge_index, x)\n",
    "\n",
    "        edge_feat_user = out[edge_index[0]]\n",
    "        edge_feat_movie = out[edge_index[1]]\n",
    "\n",
    "        return (edge_feat_user * edge_feat_movie).sum(dim=1)\n"
   ],
   "id": "398d6f686d650d86",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:17:12.193136Z",
     "start_time": "2024-11-26T01:17:12.115136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# lets split the data into training, validation, and test sets\n",
    "transform = RandomLinkSplit(\n",
    "    edge_types=('user', 'rates', 'movie'),\n",
    "    rev_edge_types=('movie', 'rev_rates', 'user')\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ],
   "id": "ea1ddba35644a207",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:08:19.442484Z",
     "start_time": "2024-11-26T00:08:19.433483Z"
    }
   },
   "cell_type": "code",
   "source": "train_data",
   "id": "3eb39937e3c1ace2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={ x=[9742, 404] },\n",
       "  user={ num_nodes=610 },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 70586],\n",
       "    time=[70586],\n",
       "    edge_label=[141172],\n",
       "    edge_label_index=[2, 141172],\n",
       "  },\n",
       "  (movie, rev_rates, user)={\n",
       "    edge_index=[2, 70586],\n",
       "    edge_label=[70586],\n",
       "    time=[70586],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:30:03.071378Z",
     "start_time": "2024-11-25T22:30:03.062379Z"
    }
   },
   "cell_type": "code",
   "source": "val_data",
   "id": "48ffa8daa4ad8cec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={ x=[9742, 404] },\n",
       "  user={ num_nodes=610 },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 70586],\n",
       "    time=[70586],\n",
       "    edge_label=[20166],\n",
       "    edge_label_index=[2, 20166],\n",
       "  },\n",
       "  (movie, rev_rates, user)={\n",
       "    edge_index=[2, 70586],\n",
       "    edge_label=[70586],\n",
       "    time=[70586],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:30:04.862378Z",
     "start_time": "2024-11-25T22:30:04.855379Z"
    }
   },
   "cell_type": "code",
   "source": "test_data",
   "id": "44e138ca692caabb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={ x=[9742, 404] },\n",
       "  user={ num_nodes=610 },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 80669],\n",
       "    time=[80669],\n",
       "    edge_label=[40334],\n",
       "    edge_label_index=[2, 40334],\n",
       "  },\n",
       "  (movie, rev_rates, user)={\n",
       "    edge_index=[2, 80669],\n",
       "    edge_label=[80669],\n",
       "    time=[80669],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:17:21.824016Z",
     "start_time": "2024-11-26T01:17:21.746010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader, NeighborLoader\n",
    "\n",
    "# Define a mini-batch loader\n",
    "num_samples = [20, 10]\n",
    "num_hops = 2\n",
    "batch_size = 128\n",
    "\n",
    "loader = LinkNeighborLoader(\n",
    "    train_data,\n",
    "    num_neighbors= num_samples,\n",
    "    batch_size=batch_size,\n",
    "    edge_label_index=(train_data.edge_types[0], train_data[train_data.edge_types[0]].edge_label_index),\n",
    "    edge_label=train_data[train_data.edge_types[0]]['edge_label'],\n",
    "    neg_sampling_ratio=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# loader = NeighborLoader(\n",
    "#     train_data,\n",
    "#     num_neighbors=num_samples * num_hops,\n",
    "#     batch_size=batch_size\n",
    "# )"
   ],
   "id": "f675bff25e347b8a",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:40:35.482807Z",
     "start_time": "2024-11-25T22:40:35.456808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampled_data = next(iter(loader))\n",
    "print(sampled_data)"
   ],
   "id": "15da3569ccfeb198",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  movie={\n",
      "    x=[2796, 404],\n",
      "    n_id=[2796],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  user={\n",
      "    num_nodes=607,\n",
      "    n_id=[607],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 17910],\n",
      "    time=[17910],\n",
      "    edge_label=[384],\n",
      "    edge_label_index=[2, 384],\n",
      "    e_id=[17910],\n",
      "    num_sampled_edges=[2],\n",
      "    input_id=[128],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 7879],\n",
      "    edge_label=[7879],\n",
      "    time=[7879],\n",
      "    e_id=[7879],\n",
      "    num_sampled_edges=[2],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T22:41:17.478602Z",
     "start_time": "2024-11-25T22:41:17.464602Z"
    }
   },
   "cell_type": "code",
   "source": "len(loader)",
   "id": "79152354f26577e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:06:40.566148Z",
     "start_time": "2024-11-26T01:06:40.554147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(sampled_data[\"user\", \"rates\", \"movie\"]['edge_label']))\n",
    "sampled_data[\"user\", \"rates\", \"movie\"]['edge_label']"
   ],
   "id": "5d8cd07aa2a721c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 5, 1, 4, 6, 6, 1, 1, 3, 5, 7, 1, 2, 5, 5, 1, 1, 4, 6, 1, 6, 1,\n",
       "        5, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 6, 6, 3, 1, 5, 1, 6, 5, 5, 1, 1, 1, 1,\n",
       "        1, 1, 6, 1, 1, 1, 1, 1, 5, 6, 5, 1, 4, 6, 1, 1, 5, 4, 1, 1, 4, 1, 1, 1,\n",
       "        1, 6, 4, 6, 5, 5, 4, 6, 1, 1, 6, 1, 1, 1, 1, 1, 6, 1, 1, 7, 5, 1, 1, 6,\n",
       "        7, 1, 6, 6, 1, 1, 3, 6, 1, 6, 1, 1, 4, 1, 1, 6, 1, 3, 5, 6, 6, 1, 1, 6,\n",
       "        1, 1, 5, 7, 4, 6, 1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:06:00.359284Z",
     "start_time": "2024-11-26T01:06:00.346284Z"
    }
   },
   "cell_type": "code",
   "source": "sampled_data[\"user\", \"rates\", \"movie\"]['edge_label_index']",
   "id": "8e798d156ed417f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 98,  60, 145, 127, 147, 201, 140,  77, 275, 197, 201, 141,  17,  34,\n",
       "          70, 134, 134, 278, 220,  84, 111, 202,  72,  88, 248,  31, 268,  69,\n",
       "         147, 125, 101, 254, 226, 224, 179,  48,  37, 182, 222,  70,  71, 158,\n",
       "         242,  52, 212, 259, 206, 154, 214,  67, 141, 199, 227, 186, 237, 133,\n",
       "         259, 279, 225, 184,  95, 115,   6, 252, 115,  53, 267,  24, 182,  30,\n",
       "           4, 119,  29, 272, 260,  57, 213, 182, 259, 259,  11, 211,  48,  50,\n",
       "         107,  47, 148, 130, 103,  35, 122,   1, 169, 280, 233, 137, 183,  76,\n",
       "         164,  85,  25, 213, 200, 152, 276, 115,  64, 269, 262, 224,  91, 281,\n",
       "         138, 229, 200,  96,  29, 265,   0,  39, 204, 173,  32,   1, 217,  84,\n",
       "         172, 241, 235,   3,  99, 210, 194, 244, 223, 142,  46,  54, 135, 178,\n",
       "         273,   8, 255, 122, 227, 248,  79, 258,   5,  42,  84, 216, 166,  62,\n",
       "         271, 111,  96, 180, 167,   9, 195,  82, 149, 102,  59,  31, 123, 187,\n",
       "         259, 208, 189, 171, 262,  19,  63, 109, 274,  83,  61,  36,  86, 198,\n",
       "          88, 229, 161,  20, 194, 196,  13,  14,  58,  80,  21, 228, 126, 192,\n",
       "          97,  72,   9, 234, 149, 282,  65, 143,  92,   3, 240, 247, 155, 221,\n",
       "         100, 174,   7, 156,  81, 122, 230, 231,  49, 108, 103, 166, 241, 162,\n",
       "         110, 168, 213,   2, 264,  56, 215,  78, 112, 200,  10, 218, 177, 114,\n",
       "         128, 270,  18, 104, 183,  94, 277, 188,  56, 115, 186,  55, 159, 200,\n",
       "         165, 253,  73,  36, 277,  43, 189, 163,  40, 113, 246, 207,  93, 238,\n",
       "         239, 124, 257, 146,   3, 170, 236,  22,  45, 121, 129, 270, 154, 256,\n",
       "          33, 251, 125, 132,  66, 170, 105, 272,  87, 106, 208, 120, 245, 270,\n",
       "         177, 250, 209, 249, 270,  19, 122, 280,  12, 219, 266, 227,  56, 266,\n",
       "          97,  68, 261,  75, 142, 185,  79,  41, 169,  15, 276, 282, 170, 243,\n",
       "         205, 131, 203, 199,  65, 140, 101,  93,  27, 118,  38,   6,  26, 202,\n",
       "         246,  90, 176, 191,  16,  51,  67, 208, 277, 117, 157,  72, 242,  41,\n",
       "         100, 190,  63, 276, 160,  95, 193, 175,  28, 139, 282, 150,  74, 162,\n",
       "         274, 253, 153,  78, 181,  57, 234, 221, 263, 151, 136, 233,  23, 238,\n",
       "          89, 104,  44, 116, 232, 144],\n",
       "        [116, 269, 367, 314, 195,  78, 189,  60, 223, 288,  59,   4,  63,  49,\n",
       "          26, 244,  94, 274, 338,  56,  13,   0,  34, 317,  18, 221, 327, 311,\n",
       "         294,   2, 193,  76, 157,  92, 322, 265,  22, 136,  64, 377, 302, 108,\n",
       "          50,  10,  83, 252, 222, 111, 306, 191,  31, 127, 277, 371,  12, 104,\n",
       "          19,  52,  42, 237,  90,  39,  11, 113,  27,   6, 355, 285, 227,  58,\n",
       "         125, 256,  89,  23, 203,  25, 242, 267, 239, 121, 340,  77, 114, 375,\n",
       "         287, 180, 336, 148,  88, 290, 186,  17,  33, 349, 183,  53,  88, 272,\n",
       "          37,  81, 165, 350, 333, 257,  32, 298, 215, 159, 352, 228, 155, 197,\n",
       "         342,  99,  82, 103, 249, 246, 346, 282,  16, 131, 235,  66,  55, 126,\n",
       "         251,  36,  69, 270, 255, 297, 167, 145, 224, 141, 234, 354, 140,  84,\n",
       "         276, 146, 107,  40, 243, 304, 334, 271,  68, 329, 216, 201, 296,  87,\n",
       "         273, 170, 248, 372, 154, 115, 117,  41, 122, 133, 211, 218, 172, 158,\n",
       "         324, 315, 144,  45,  86, 300, 330, 130, 339, 128, 282, 337,  74, 326,\n",
       "          95,   5,  47, 254, 258, 198, 110, 358,  71, 365, 320, 295, 134, 316,\n",
       "         164, 163, 119, 232, 169, 139, 263, 153, 289,  44, 219, 313,  96, 175,\n",
       "         173, 335,  48, 179, 245, 149,  93,   1,  35, 161, 174, 240,  70, 210,\n",
       "         309,  98, 200, 199, 217,  21, 143, 264,  20, 370, 301, 168, 361, 220,\n",
       "         152, 178, 259, 129, 308, 369, 124, 207,  62, 321, 319, 185, 112, 343,\n",
       "         366, 204, 109,   7, 266, 364, 310,  72, 120,  65, 162, 260, 206,  85,\n",
       "         247, 150,   9, 118, 353,  97, 362, 196, 177, 279,  73, 250, 132,  79,\n",
       "         278, 341, 356,  28, 345,  51, 318, 360, 344, 363, 100, 192, 225,  67,\n",
       "         347, 325, 170, 299, 102, 292, 281, 202, 106, 284, 205, 283, 166, 190,\n",
       "         312, 123, 138, 229, 160, 280,  54, 142, 357, 184, 231,  14,  61, 151,\n",
       "           2,  57,  24, 307, 286,  91,  75, 137,  80, 176,  43, 188, 328, 135,\n",
       "         226, 293, 236, 348, 331, 212, 275, 323, 359, 261, 156, 208, 209, 101,\n",
       "         238, 194, 303,   3, 210, 332, 305,  38,  29, 241, 181, 268, 168, 351,\n",
       "          15,  30, 182, 376,   8, 373, 262, 147,  46, 291, 105, 368, 253, 233,\n",
       "         213, 171, 187, 230, 214, 374]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:17:27.627093Z",
     "start_time": "2024-11-26T01:17:27.563092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_of_epochs = 10\n",
    "model = GNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ],
   "id": "91e2bd7d8c3e77f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (gnn_layer_1): GNNLayer()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T02:09:05.737433Z",
     "start_time": "2024-11-26T02:09:05.715433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, batch):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch.to(device)\n",
    "\n",
    "    target = batch['user', 'rates', 'movie'].edge_label.to(device).to(torch.float64)\n",
    "\n",
    "    pred = model(batch['user','rates', 'movie'].edge_label_index, batch[\"movie\"].x)\n",
    "\n",
    "    loss = F.mse(pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return pred, loss"
   ],
   "id": "ad08b6c3df59cb07",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T02:09:36.364666Z",
     "start_time": "2024-11-26T02:09:36.256666Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, sampled_data)",
   "id": "d98f361586add0ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.1088e+14,  2.2519e+14,  3.9070e+12,  3.1812e+14,  1.5204e+13,\n",
       "          4.4266e+14,  5.6005e+13,  2.4818e+14,  2.4148e+12,  1.0819e+14,\n",
       "          5.1214e+14,  1.0722e+14,  2.6487e+14,  1.6070e+14,  4.2657e+14,\n",
       "          4.4054e+13,  1.5941e+14,  2.0803e+14,  3.0544e+13,  5.7222e+13,\n",
       "          4.5635e+14,  1.5069e+14,  1.7184e+14,  2.7676e+14,  5.0512e+14,\n",
       "          8.9223e+14,  5.9364e+13,  1.2541e+13,  8.6922e+12,  4.2534e+14,\n",
       "          1.1235e+14,  6.5642e+13,  4.3145e+13,  3.6124e+13,  2.0093e+13,\n",
       "          8.4702e+13,  8.6053e+14,  8.6622e+13,  4.3207e+13,  9.3353e+12,\n",
       "          6.8015e+13,  1.2616e+15,  9.5460e+13,  4.4821e+14,  6.0252e+13,\n",
       "          5.0503e+13,  1.8754e+13,  7.0613e+13,  9.7298e+12,  6.8861e+13,\n",
       "          1.8519e+14,  3.6206e+14,  1.7288e+13, -2.4414e+09,  3.4143e+13,\n",
       "          1.1475e+14,  1.0412e+14,  5.6317e+12,  1.8534e+14,  7.6671e+13,\n",
       "          1.2252e+13,  6.6338e+12,  1.0331e+15,  1.0099e+14,  1.0050e+13,\n",
       "          7.6862e+14,  1.0103e+13,  2.6148e+13,  3.2637e+13,  1.5432e+13,\n",
       "          1.0115e+14,  6.6839e+14,  6.1351e+13,  7.5055e+12,  3.5538e+14,\n",
       "          4.3142e+14,  4.7738e+13,  6.8112e+13,  6.8454e+13,  1.2448e+14,\n",
       "          1.0790e+14, -4.8841e+08,  6.2203e+14, -9.0511e+09,  4.4717e+14,\n",
       "          3.0518e+13,  2.1397e+13,  6.6175e+13,  1.6560e+15,  1.4653e+13,\n",
       "          5.2468e+13,  1.2641e+14,  1.2840e+14,  8.4243e+12,  1.0097e+14,\n",
       "          6.2119e+13,  8.4092e+14,  5.3806e+12,  1.9417e+14,  1.5479e+14,\n",
       "          1.8683e+14,  5.8404e+12,  3.7948e+12,  3.4580e+14,  5.8884e+14,\n",
       "          7.8205e+11,  2.5263e+13,  6.2620e+13,  7.2274e+12,  4.0634e+13,\n",
       "          1.3376e+14,  2.6534e+14,  3.1207e+12,  6.4254e+13,  2.2232e+13,\n",
       "          3.3397e+14,  9.7724e+13,  2.5747e+13, -3.8243e+09,  1.1329e+14,\n",
       "          1.5440e+14,  1.8846e+14,  7.1420e+14,  1.7592e+14,  5.4184e+13,\n",
       "          6.0714e+13,  8.3696e+13,  1.9381e+14,  9.5811e+13,  1.9517e+14,\n",
       "          6.9082e+13,  1.7295e+13,  1.0731e+13,  7.4248e+12,  1.5290e+12,\n",
       "          7.5255e+13,  1.9354e+14,  9.2210e+12,  3.7922e+13,  5.3076e+13,\n",
       "          4.4207e+13,  6.5376e+13,  7.0905e+13,  8.0064e+13,  3.2441e+13,\n",
       "          2.8494e+14,  4.3161e+13,  4.4349e+13,  1.3271e+12, -5.8009e+09,\n",
       "          7.5447e+13,  1.8470e+14,  1.3140e+13,  9.7428e+13,  1.1807e+13,\n",
       "          4.5223e+13,  5.5065e+14,  6.9538e+12,  3.4293e+13,  1.2790e+13,\n",
       "          6.6490e+13,  5.4007e+13,  3.4081e+13,  1.3214e+14, -2.3598e+09,\n",
       "          2.4737e+14,  5.2353e+13,  2.0667e+14,  4.5658e+12,  2.4845e+13,\n",
       "          1.1086e+14,  3.9483e+14,  2.9201e+13,  9.5354e+13,  8.6589e+13,\n",
       "          9.2794e+13,  1.7828e+14,  5.7279e+13,  4.9466e+13, -1.6702e+10,\n",
       "          9.5861e+13,  1.0088e+12,  2.4259e+14,  6.1748e+13,  6.3037e+13,\n",
       "          3.5692e+13,  2.7141e+13,  4.0118e+13,  6.9170e+09,  8.3079e+13,\n",
       "          1.6696e+13, -1.9673e+10, -3.9894e+09,  6.7573e+12,  1.1973e+14,\n",
       "          3.7308e+13,  7.1287e+13,  1.2831e+14,  2.1536e+15,  3.8168e+13,\n",
       "          3.1359e+13,  7.1790e+13,  4.8921e+13,  1.3696e+14,  7.9755e+13,\n",
       "          3.1479e+14,  3.9273e+13,  1.3864e+13,  3.9006e+14,  4.9701e+14,\n",
       "          2.8335e+13,  2.3256e+13,  4.5956e+14,  4.5326e+13,  1.5824e+14,\n",
       "          3.4081e+13,  3.2548e+14,  3.6618e+13,  9.3024e+13,  4.9719e+14,\n",
       "          1.2615e+14,  5.0193e+13,  5.7275e+13,  7.6437e+13,  8.0637e+08,\n",
       "          9.7155e+13,  2.4094e+13,  5.1451e+14, -1.1056e+09,  1.0349e+14,\n",
       "          4.1822e+13, -1.3608e+10,  9.4832e+13,  5.3082e+12,  4.9668e+13,\n",
       "          1.3334e+14,  2.8895e+13,  4.9370e+14,  1.1455e+14,  6.2679e+13,\n",
       "          1.2319e+14,  2.2184e+14,  5.8066e+12,  8.2625e+13,  5.3785e+13,\n",
       "         -1.8476e+09,  7.4264e+13,  1.3472e+12,  9.2463e+12,  7.0619e+13,\n",
       "          1.2073e+14,  1.3797e+12,  1.3841e+13,  1.9529e+14,  1.2531e+14,\n",
       "          6.1521e+14,  2.5652e+13,  9.5478e+13,  4.8019e+13,  1.2831e+14,\n",
       "          3.8970e+13,  7.7097e+13,  4.6488e+13,  7.2386e+13,  7.9920e+13,\n",
       "          8.8614e+13,  8.0844e+13,  1.3683e+14,  7.7622e+14,  4.1652e+13,\n",
       "          6.0491e+13,  4.5647e+13,  1.1008e+13,  5.0854e+14,  2.2067e+14,\n",
       "          1.0967e+13,  1.7328e+14,  1.1371e+14,  7.9815e+13,  9.4255e+13,\n",
       "          3.1514e+14,  3.3961e+13,  4.3490e+13,  7.6240e+12,  2.6910e+13,\n",
       "          4.2360e+13,  1.6958e+13,  2.0816e+12,  7.3819e+12,  7.7924e+13,\n",
       "          2.2080e+13,  1.5765e+13,  8.0307e+13,  3.4930e+13,  3.8646e+13,\n",
       "          8.8461e+13,  8.6120e+13,  1.5007e+13,  8.6669e+13,  1.0120e+14,\n",
       "          6.0242e+13,  4.7157e+13,  1.4202e+14,  3.0903e+13,  6.1635e+13,\n",
       "          2.2321e+13,  4.7768e+13,  6.0348e+13,  1.2281e+14,  5.4095e+11,\n",
       "          6.4057e+13,  1.3517e+14,  2.8953e+13,  1.4756e+13,  1.1391e+14,\n",
       "          4.6551e+13,  4.0826e+12,  5.1371e+14,  5.9903e+13,  2.2564e+14,\n",
       "          4.2221e+13,  1.7005e+14,  5.1325e+14,  1.7610e+14,  2.6568e+14,\n",
       "          4.8690e+13,  4.1184e+13,  3.1667e+13,  2.4083e+14,  9.8488e+13,\n",
       "          1.0577e+15,  5.4553e+13,  5.1731e+14, -1.2632e+10,  5.4397e+14,\n",
       "          1.1960e+14,  5.3569e+13,  1.8127e+13,  3.4552e+13,  1.2385e+13,\n",
       "         -5.8481e+09,  6.1453e+13,  4.4678e+13,  1.2412e+13,  2.2457e+13,\n",
       "          5.2197e+13,  2.5916e+13,  1.0519e+14,  6.0937e+13,  5.6188e+13,\n",
       "          1.9688e+13,  2.6278e+13,  1.9738e+13,  5.5808e+14,  3.9444e+13,\n",
       "          9.9027e+12,  1.4191e+14,  2.8363e+14,  9.3497e+12,  6.0653e+13,\n",
       "          1.0903e+14,  9.5661e+13,  1.4554e+14,  6.8225e+13,  3.3896e+14,\n",
       "          2.5743e+14,  1.1246e+14, -2.2432e+10,  1.6914e+14,  3.3739e+13,\n",
       "          2.4005e+13,  8.5577e+13,  2.0308e+14,  2.1283e+14,  6.8589e+13,\n",
       "          4.7286e+13,  2.7062e+14,  1.4010e+14,  6.6030e+13,  1.8549e+14,\n",
       "          8.0762e+13,  1.3251e+14,  4.1172e+13,  2.1698e+13], device='cuda:0',\n",
       "        grad_fn=<SumBackward1>),\n",
       " tensor(-1.0501e+14, device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<BinaryCrossEntropyWithLogitsBackward0>))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:19:02.005756Z",
     "start_time": "2024-11-26T01:17:42.294816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tqdm\n",
    "from torch.nn import functional as F\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_of_epochs):\n",
    "    total_loss = total_examples = 0.0\n",
    "    for batch in tqdm.tqdm(loader):\n",
    "        pred, loss = train_model(model, batch)\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "    print(f\"Epoch: {epoch:03d}, loss: {total_loss/total_examples:.4f}\")\n"
   ],
   "id": "76dfbbb7476a689b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1103/1103 [00:12<00:00, 87.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, loss: -213068739744.4834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1103/1103 [00:12<00:00, 88.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, loss: -2642091958241.2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1103/1103 [00:12<00:00, 86.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, loss: -11126041355296.2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1103/1103 [00:12<00:00, 88.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, loss: -29832610421403.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1103/1103 [00:12<00:00, 88.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, loss: -62593995361581.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1103/1103 [00:12<00:00, 88.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, loss: -114272206584038.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 377/1103 [00:04<00:08, 87.55it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[194], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     18\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 19\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m pred\u001B[38;5;241m.\u001B[39mnumel()\n\u001B[0;32m     20\u001B[0m     total_examples \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m pred\u001B[38;5;241m.\u001B[39mnumel()\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_loss\u001B[38;5;241m/\u001B[39mtotal_examples\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3224abf4b5876e8c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
