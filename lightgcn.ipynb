{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim, Tensor\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.datasets import AmazonBook, MovieLens\n",
    "from torch_geometric.transforms import Compose, ToDevice, ToUndirected\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.utils import train_test_split_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(MessagePassing): \n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        edge_index_norm = self._compute_normalized_adjacency(edge_index)\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1) \n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items]) \n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "    def _compute_normalized_adjacency(self, edge_index: SparseTensor) -> SparseTensor:\n",
    "        \"\"\"Compute normalized adjacency matrix A' = D^(-1/2) * A * D^(-1/2)\"\"\"\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index,\n",
    "            add_self_loops=self.add_self_loops\n",
    "        ) \n",
    "        return edge_index_norm\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        return matmul(adj_t, x)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2)) \n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) \n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) \n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(batch_size, edge_index):\n",
    " # returns a tuple of 3 tensors. Tensor 1 -> user, Tensor 2 -> positive interactions, Tensor3-> Neg interactions\n",
    "   print(\"Original edge_index:\")\n",
    "   print(edge_index)\n",
    "   print(f\"Edge index shape: {edge_index.shape}\")\n",
    "   edges = structured_negative_sampling(edge_index)\n",
    "   edges = torch.stack(edges, dim=0)\n",
    "   print(\"\\nAfter negative sampling (first 5 samples):\")\n",
    "   print(\"Format: [user_indices, pos_item_indices, neg_item_indices]\")\n",
    "   print(edges[:, :5])  # Show first 5 samples\n",
    "   indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "   batch = edges[:, indices]\n",
    "   user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "   return user_indices, pos_item_indices, neg_item_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user efficiently.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges \n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {user.item(): [] for user in edge_index[0].unique()}\n",
    "    for user, item in zip(edge_index[0], edge_index[1]):\n",
    "        user_pos_items[user.item()].append(item.item())\n",
    "\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(groundTruth, r, k):\n",
    "    num_correct_pred = torch.sum(r, dim=-1).float()\n",
    "    user_num_liked = torch.tensor([len(groundTruth[i]) for i in range(len(groundTruth))], dtype=torch.float) \n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wrapper function to get evaluation metrics\n",
    "# def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "#     \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "#     Args:\n",
    "#         model (LighGCN): lightgcn model\n",
    "#         edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "#         exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "#         k (int): determines the top k items to compute metrics on\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: recall @ k, precision @ k, ndcg @ k\n",
    "#     \"\"\"\n",
    "#     user_embedding = model.users_emb.weight\n",
    "#     item_embedding = model.items_emb.weight\n",
    "\n",
    "#     rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "#     for exclude_edge_index in exclude_edge_indices:\n",
    "#         user_pos_items = get_ground_truth(exclude_edge_index)\n",
    "#         exclude_users = []\n",
    "#         exclude_items = []\n",
    "#         for user, items in user_pos_items.items():\n",
    "#             exclude_users.extend([user] * len(items))\n",
    "#             exclude_items.extend(items)\n",
    "\n",
    "#         rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "#     _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "#     users = edge_index[0].unique()\n",
    "\n",
    "#     test_user_pos_items = get_ground_truth(edge_index)\n",
    "\n",
    "#     test_user_pos_items_list = [\n",
    "#         test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "#     r = []\n",
    "#     for user in users:\n",
    "#         ground_truth_items = test_user_pos_items[user.item()]\n",
    "#         label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "#         r.append(label)\n",
    "#     r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "#     recall, precision = metrics(test_user_pos_items_list, r, k)\n",
    "#     # ndcg = \n",
    "\n",
    "#     return recall, precision, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "#     \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "#     Args:\n",
    "#         model (LighGCN): lightgcn model\n",
    "#         edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "#         sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "#         exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "#         k (int): determines the top k items to compute metrics on\n",
    "#         lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "#     \"\"\"\n",
    "#     users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "#         sparse_edge_index)\n",
    "#     edges = structured_negative_sampling(\n",
    "#         edge_index, contains_neg_self_loops=False)\n",
    "#     user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "#     users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "#     pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "#         pos_item_indices], items_emb_0[pos_item_indices]\n",
    "#     neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "#         neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "#     loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "#                     neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    "\n",
    "#     recall, precision, ndcg = get_metrics(\n",
    "#         model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "#     return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATIONS = 10000\n",
    "# BATCH_SIZE = 1024\n",
    "# LR = 1e-3\n",
    "# ITERS_PER_EVAL = 200\n",
    "# ITERS_PER_LR_DECAY = 200\n",
    "# K = 20\n",
    "# LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_tensors = torch.load('sparse_tensors.pt')\n",
    "# train_sparse = saved_tensors['train_sparse']\n",
    "# val_sparse = saved_tensors['val_sparse']\n",
    "# test_sparse = saved_tensors['test_sparse']\n",
    "\n",
    "# sparse_sizes = train_sparse.sparse_sizes()\n",
    "# num_users = num_items = sparse_sizes[0] // 2\n",
    "# print(f\"Number of users/items: {num_users}\")\n",
    "\n",
    "# train_edge_index = torch.stack([train_sparse.storage.row(), train_sparse.storage.col()])\n",
    "# val_edge_index = torch.stack([val_sparse.storage.row(), val_sparse.storage.col()])\n",
    "\n",
    "# model = LightGCN(\n",
    "#     num_users=num_users,\n",
    "#     num_items=num_items,\n",
    "#     embedding_dim=64,\n",
    "#     K=3\n",
    "# )\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using device {device}\")\n",
    "\n",
    "# model = model.to(device)\n",
    "# model.train()\n",
    "\n",
    "# train_edge_index = train_edge_index.to(device)\n",
    "# val_edge_index = val_edge_index.to(device)\n",
    "# train_sparse = train_sparse.to(device)\n",
    "# val_sparse = val_sparse.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)  \n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "# print(f\"Training setup complete. Ready to train on {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# for iter in range(ITERATIONS):\n",
    "#    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "#        train_sparse)  \n",
    "\n",
    "#    user_indices, pos_item_indices, neg_item_indices = sample_batch(\n",
    "#        BATCH_SIZE, train_edge_index)\n",
    "#    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "#        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "#    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "#    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "#        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "#    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "#        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "#    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "#                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    "\n",
    "#    optimizer.zero_grad()\n",
    "#    train_loss.backward()\n",
    "#    optimizer.step()\n",
    "\n",
    "#    if iter % ITERS_PER_EVAL == 0:\n",
    "#        model.eval()\n",
    "#        val_loss, recall, precision, ndcg = evaluation(\n",
    "#            model, val_edge_index, val_sparse, [train_edge_index], K, LAMBDA)  \n",
    "#        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "#        train_losses.append(train_loss.item())\n",
    "#        val_losses.append(val_loss)\n",
    "#        model.train()\n",
    "\n",
    "#    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "#        scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
